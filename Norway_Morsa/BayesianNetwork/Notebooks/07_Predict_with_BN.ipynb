{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, os\n",
    "import bayes_net_utils as bn\n",
    "pd.options.display.width=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian network predictions\n",
    "\n",
    "The R code required to run the Bayesian network and generate predictions has been refactored into the R function `bayes_net_predict` in `bayes_net_utils.R`. There is also a Python function of the same name in `bayes_net_utils.py`, which provides a simple \"wrapper\" around the R fucntion and some minor additional calculations. This should make it easy to make predictions from the Bayesian network via Python.\n",
    "\n",
    "**Note:** There is some computational overhead involved in interfacing between Python and R, but this isn't a major problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User options\n",
    "\n",
    "run_mode = 'Historic'        # Run mode? 'Historic' for period 1981-2018/19, or 'NextSeason' for future (operational, or one historic test season)\n",
    "\n",
    "if run_mode == 'NextSeason': # If making predictions for the next season, for which year? For file reading\n",
    "    target_yr = 2020\n",
    "\n",
    "# Also run the combination of models selected as 'best' for each variable?\n",
    "# If set to True, you MUST also set met_evidence = 'era5-av'\n",
    "run_operational = True # Boolean (True or False)\n",
    "    \n",
    "met_evidence = 'era5-av'  # Source of met data used to create data for driving predictions? 'metno', 'era5', 'era5-av', or 's5'\n",
    "\n",
    "# Use dictionary to automatically set the met data used in network training based on the source of data used to drive predictions.\n",
    "# If met data for predictions is not s5, should be the same as met_evidence. If 's5', should be 'era5' as that was used in bias correcting s5\n",
    "met_training_dict = {'metno':'metno',\n",
    "                    'era5':'era5',\n",
    "                    's5':'era5',\n",
    "                    'era5-av':'era5'}\n",
    "met_training = met_training_dict[met_evidence]\n",
    "\n",
    "# Start and end years of data used to fit network (used in the .rds filepath) and, for 'Historic' run_mode,\n",
    "# in generating the data for prediction (and in the filepaths to these csvs)\n",
    "st_end_yr_dict = {'metno': [1981,2018],\n",
    "               'era5': [1981,2019],\n",
    "               'era5-av': [1981,2019],\n",
    "               's5': [1993,2019]}\n",
    "\n",
    "# Fitted bnlearn object\n",
    "rfile_fpath = \"../Data/RData/Vansjo_fitted_GaussianBN_%s_%s-%s.rds\" %(met_training, st_end_yr_dict[met_training][0], st_end_yr_dict[met_training][1])\n",
    "\n",
    "# Pre-calculated standard deviations\n",
    "sd_fpath = \"../Data/FittedNetworkDiagnostics/GBN_%s_%s-%s_stdevs.csv\" %(met_training, st_end_yr_dict[met_training][0], st_end_yr_dict[met_training][1])\n",
    "\n",
    "# The 'evidence' (data that will be used to drive the predictions) folder\n",
    "ev_folder = r'../Data/DataForPrediction/%s/%s' %(run_mode, met_evidence)\n",
    "\n",
    "# Outfolder to save predictions in\n",
    "out_folder = r'../Data/Predictions/%s' %run_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to predict multiple years at once\n",
    "\n",
    "If you are just predicting for one season, you can use bn.bayes_net_predict by itself. The function below works too, but is particularly useful for producing predictions for all years in a historic test period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_predict_multipleyears(rfile_fpath, sd_fpath, ev_df):\n",
    "    \"\"\"\n",
    "    Loop over rows in evidence dataframe and make predictions for each row (year), and concatenate results into a\n",
    "    single df\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    for idx, row in ev_df.iterrows():\n",
    "        # Run Bayesian network in R\n",
    "        df = bn.bayes_net_predict(rfile_fpath,\n",
    "                                  sd_fpath,\n",
    "                                  float(row['year']),\n",
    "                                  float(row['chla_prevSummer']),\n",
    "                                  float(row['colour_prevSummer']),\n",
    "                                  float(row['TP_prevSummer']),\n",
    "                                  float(row['wind_speed']),\n",
    "                                  float(row['rain']),\n",
    "                                 )\n",
    "    #     # Add 'year' to results as unique identifier\n",
    "    #     df['year'] = int(row['year'])\n",
    "        df_list.append(df)\n",
    "\n",
    "    # Merge results from all years\n",
    "    df = pd.concat(df_list, sort=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Re-order cols\n",
    "    df = df[['year', 'node', 'threshold','prob_below_threshold', \n",
    "             'prob_above_threshold', 'expected_value', 'sd','WFD_class']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for 'deterministic' met data (e.g. met.no or ERA5)\n",
    "\n",
    "Where there is just a single 'evidence' datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>node</th>\n",
       "      <th>threshold</th>\n",
       "      <th>prob_below_threshold</th>\n",
       "      <th>prob_above_threshold</th>\n",
       "      <th>expected_value</th>\n",
       "      <th>sd</th>\n",
       "      <th>WFD_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981</td>\n",
       "      <td>chla</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>19.000</td>\n",
       "      <td>3.760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981</td>\n",
       "      <td>colour</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.02</td>\n",
       "      <td>28.900</td>\n",
       "      <td>9.040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981</td>\n",
       "      <td>cyano</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.970</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981</td>\n",
       "      <td>TP</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>37.000</td>\n",
       "      <td>3.790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1982</td>\n",
       "      <td>chla</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.03</td>\n",
       "      <td>12.300</td>\n",
       "      <td>3.760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2018</td>\n",
       "      <td>TP</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>23.200</td>\n",
       "      <td>3.790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2019</td>\n",
       "      <td>chla</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11.000</td>\n",
       "      <td>3.760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2019</td>\n",
       "      <td>colour</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>36.800</td>\n",
       "      <td>9.040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2019</td>\n",
       "      <td>cyano</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2019</td>\n",
       "      <td>TP</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.03</td>\n",
       "      <td>22.600</td>\n",
       "      <td>3.790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year    node  threshold  prob_below_threshold  prob_above_threshold  \\\n",
       "0    1981    chla       20.0                  0.60                  0.40   \n",
       "1    1981  colour       48.0                  0.98                  0.02   \n",
       "2    1981   cyano        1.0                  0.26                  0.74   \n",
       "3    1981      TP       29.5                  0.02                  0.98   \n",
       "4    1982    chla       20.0                  0.97                  0.03   \n",
       "..    ...     ...        ...                   ...                   ...   \n",
       "151  2018      TP       29.5                  0.95                  0.05   \n",
       "152  2019    chla       20.0                  0.99                  0.01   \n",
       "153  2019  colour       48.0                  0.89                  0.11   \n",
       "154  2019   cyano        1.0                  0.80                  0.20   \n",
       "155  2019      TP       29.5                  0.97                  0.03   \n",
       "\n",
       "     expected_value     sd  WFD_class  \n",
       "0            19.000  3.760          0  \n",
       "1            28.900  9.040          0  \n",
       "2             1.970  0.719          1  \n",
       "3            37.000  3.790          1  \n",
       "4            12.300  3.760          0  \n",
       "..              ...    ...        ...  \n",
       "151          23.200  3.790          0  \n",
       "152          11.000  3.760          0  \n",
       "153          36.800  9.040          0  \n",
       "154           0.413  0.719          0  \n",
       "155          22.600  3.790          0  \n",
       "\n",
       "[156 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if met_evidence !='s5':\n",
    "    \n",
    "    # Sort out filepaths for the evidence data to read in and the output file\n",
    "    if run_mode == 'NextSeason':\n",
    "        ev_fname = 'DataForPrediction_GBN_%s_%s.csv' %(met_evidence, target_yr)\n",
    "        out_fname = 'GBN_prediction_%s_%s.csv' %(met_evidence, target_yr)\n",
    "    else:\n",
    "        ev_fname = 'DataForPrediction_GBN_%s_%s-%s.csv' %(met_evidence, st_end_yr_dict[met_evidence][0], st_end_yr_dict[met_evidence][1])\n",
    "        out_fname = 'GBN_prediction_%s_%s-%s.csv' %(met_evidence, st_end_yr_dict[met_evidence][0], st_end_yr_dict[met_evidence][1])\n",
    "        \n",
    "    ev_path = os.path.join(ev_folder, ev_fname)\n",
    "    out_path = os.path.join(out_folder, out_fname)\n",
    "    \n",
    "    # Read in evidence and optionally display\n",
    "    ev_df = pd.read_csv(ev_path)\n",
    "    \n",
    "#     display(ev_df.head())\n",
    "    \n",
    "    # Predict and save to csv\n",
    "    df = bn_predict_multipleyears(rfile_fpath, sd_fpath, ev_df)\n",
    "    \n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions using evidence derived from seasonal forecast data\n",
    "\n",
    "Where there may be multiple seasons and members. Currently set up for System5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if met_evidence == 's5':\n",
    "    \n",
    "    member_li = [\"%.2d\" % i for i in range(1,26)] # List of S5 member numbers in format '01','02'... Should be present in s5 met data folder\n",
    "    season_li = ['summer','late_summer'] # Seasons of interest (must match filenames in s5 met data folder)\n",
    "\n",
    "    for season in season_li:\n",
    "        for member in member_li:\n",
    "\n",
    "            # Sort out filepaths for the evidence data to read in and the output file\n",
    "            if run_mode == 'NextSeason':\n",
    "                ev_fname = 'DataForPrediction_GBN_%s_%s_%s_%s.csv' %(met_evidence, target_yr, season, member)\n",
    "                out_fname = 'GBN_prediction_%s_%s_%s_%s.csv' %(met_evidence, target_yr, season, member)\n",
    "            else:\n",
    "                ev_fname = 'DataForPrediction_GBN_%s_%s-%s_%s_%s.csv' %(met_evidence, st_end_yr_dict[met_evidence][0], st_end_yr_dict[met_evidence][1], season, member)\n",
    "                out_fname = 'GBN_prediction_%s_%s-%s_%s_%s.csv' %(met_evidence, st_end_yr_dict[met_evidence][0], st_end_yr_dict[met_evidence][1], season, member)\n",
    "\n",
    "            ev_path = os.path.join(ev_folder, ev_fname)\n",
    "            out_path = os.path.join(out_folder, 's5', out_fname)\n",
    "\n",
    "            # Read in evidence\n",
    "            ev_df = pd.read_csv(ev_path)\n",
    "\n",
    "            # Predict and save to csv\n",
    "            df = bn_predict_multipleyears(rfile_fpath, sd_fpath, ev_df)\n",
    "            df.to_csv(out_path, index=False)\n",
    "\n",
    "    # Display output for the last season and member for checking\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplest possible model: target season = previous season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>node</th>\n",
       "      <th>expected_value</th>\n",
       "      <th>WFD_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2015</td>\n",
       "      <td>colour</td>\n",
       "      <td>41.863636</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2016</td>\n",
       "      <td>colour</td>\n",
       "      <td>52.833333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2017</td>\n",
       "      <td>colour</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2018</td>\n",
       "      <td>colour</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2019</td>\n",
       "      <td>colour</td>\n",
       "      <td>36.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year    node  expected_value  WFD_class\n",
       "151  2015  colour       41.863636        0.0\n",
       "152  2016  colour       52.833333        1.0\n",
       "153  2017  colour       52.000000        1.0\n",
       "154  2018  colour       42.000000        0.0\n",
       "155  2019  colour       36.333333        0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obs_fpath = '../Data/DataMatrices/Seasonal_BN_obs/seasonal_obs_GBN_1980-2019.csv'\n",
    "\n",
    "# Read in evidence and optionally display\n",
    "seasonal_obs_df = pd.read_csv(obs_fpath, index_col=0)\n",
    "# display(obs_df.head())\n",
    "\n",
    "# Fill NaNs in water chemistry and ecology (linearly interpolate and backwards fill)\n",
    "# seasonal_obs_df.interpolate(method='linear',limit=1, inplace=True)\n",
    "\n",
    "# Predict\n",
    "naive_sim_df_wide = seasonal_obs_df.shift(+1).loc[1981:]\n",
    "\n",
    "# Reformat to long format\n",
    "naive_sim_df_wide = naive_sim_df_wide.reset_index()\n",
    "sim_naive = pd.melt(naive_sim_df_wide,\n",
    "                    id_vars=['year'],\n",
    "                    value_vars=['TP','chla','cyano','colour'],\n",
    "                    var_name='node',\n",
    "                    value_name='expected_value')\n",
    "\n",
    "# Add predicted class\n",
    "# Dictionary of thresholds to use. N.B. Also defined in bayes_net_utils.R (as boundaries_list)\n",
    "boundaries_dict = {'TP': 29.5,     # Middle of 'Moderate' class\n",
    "                   'chla': 20.0,   # M-P boundary. WFD boundaries: [10.5, 20.0]. Only 6 observed points under 10.5 so merge G & M\n",
    "                   'colour': 48.0, # 66th percentile (i.e. upper tercile). No management implications\n",
    "                   'cyano': 1.0    # M-P boundary is 2.0, but there were only 2 values in this class. Plenty above 2 tho\n",
    "                  }\n",
    "sim_naive['WFD_class'] = sim_naive[['node','expected_value']].apply(lambda x: bn.discretize([boundaries_dict[x.node]],\n",
    "                                                                                                 x.expected_value), axis=1)\n",
    "# Save to csv\n",
    "if run_mode == 'NextSeason':\n",
    "    out_fname = 'Prediction_naive_%s.csv' %(target_yr)\n",
    "else:\n",
    "    out_fname = 'Prediction_naive_%s-%s.csv' %(st_end_yr_dict[met_evidence][0], st_end_yr_dict[met_evidence][1])\n",
    "out_path = os.path.join(out_folder, out_fname)\n",
    "\n",
    "sim_naive.to_csv(out_path)\n",
    "\n",
    "display(sim_naive.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historic predictions from chosen 'operational' models\n",
    "\n",
    "All forecasts were originally going to be based on a Bayesian Belief Network (BBN) which included several weather-related nodes (mean seasonal wind speed and seasonal precipitation sum). However, the results of cross validation of the Bayesian Network and different versions of the ntework (notebook BN_CV_PythonPostProcess), and a comparison of different models for the hindcast period (notebook Hindcast_stats_and_plots), lead to the following choices for models to use in operational forecasting:\n",
    "\n",
    "- TP: BBN (no met included anyway in BN)\n",
    "- chla: Naive seasonal forecast\n",
    "- colour: BBN, no met (stats were the same for BBN with met, without met, or seasonal naive. Choose this for consistency with cyano)\n",
    "- cyano: BBN, no met\n",
    "\n",
    "Here, produce forecasts for the historic period using this model choice\n",
    "\n",
    "**Note**: For now I decided to leave any NaNs in the seasonal naive forecast (think there's just one in 2000, due to no chla obs in 1999). There aren't corresponding NaNs in the BN though, despite missing data... Should perhaps interpolate for consistency? Or drop BN predictions in years with missing lake chem/ecol data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_predict_multipleyears_operational(rfile_fpath, ev_df):\n",
    "    \"\"\"\n",
    "    Loop over rows in evidence dataframe and make predictions for each row (year),\n",
    "    and concatenate results into a single df\n",
    "    \n",
    "    The same as bn_predict_multipleyears, but calls the function bayes_net_predict_operational,\n",
    "    rather than bayes_net_predict. This makes almost no difference to the results, but it does\n",
    "    make a tiny difference, so worth doing just for consistency across prediction notebooks.\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    for idx, row in ev_df.iterrows():\n",
    "        # Run Bayesian network in R\n",
    "        df = bn.bayes_net_predict_operational(rfile_fpath,\n",
    "                                  float(row['year']),\n",
    "                                  float(row['chla_prevSummer']),\n",
    "                                  float(row['colour_prevSummer']),\n",
    "                                  float(row['TP_prevSummer'])\n",
    "                                             )\n",
    "        df_list.append(df)\n",
    "\n",
    "    # Merge results from all years\n",
    "    df = pd.concat(df_list, sort=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Re-order cols\n",
    "    df = df[['year', 'node', 'threshold','prob_below_threshold', \n",
    "             'prob_above_threshold', 'expected_value', 'WFD_class']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>node</th>\n",
       "      <th>expected_value</th>\n",
       "      <th>WFD_class</th>\n",
       "      <th>threshold</th>\n",
       "      <th>prob_below_threshold</th>\n",
       "      <th>prob_above_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981</td>\n",
       "      <td>chla</td>\n",
       "      <td>16.08013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1982</td>\n",
       "      <td>chla</td>\n",
       "      <td>8.33125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1983</td>\n",
       "      <td>chla</td>\n",
       "      <td>5.97500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984</td>\n",
       "      <td>chla</td>\n",
       "      <td>6.05000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>chla</td>\n",
       "      <td>11.09000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2018</td>\n",
       "      <td>cyano</td>\n",
       "      <td>0.44700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2018</td>\n",
       "      <td>TP</td>\n",
       "      <td>23.10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2019</td>\n",
       "      <td>colour</td>\n",
       "      <td>36.80000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2019</td>\n",
       "      <td>cyano</td>\n",
       "      <td>0.40800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2019</td>\n",
       "      <td>TP</td>\n",
       "      <td>22.60000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year    node  expected_value  WFD_class  threshold  prob_below_threshold  \\\n",
       "0    1981    chla        16.08013        0.0       20.0                   NaN   \n",
       "1    1982    chla         8.33125        0.0       20.0                   NaN   \n",
       "2    1983    chla         5.97500        0.0       20.0                   NaN   \n",
       "3    1984    chla         6.05000        0.0       20.0                   NaN   \n",
       "4    1985    chla        11.09000        0.0       20.0                   NaN   \n",
       "..    ...     ...             ...        ...        ...                   ...   \n",
       "151  2018   cyano         0.44700        0.0        1.0                  0.78   \n",
       "152  2018      TP        23.10000        0.0       29.5                  0.95   \n",
       "153  2019  colour        36.80000        0.0       48.0                  0.88   \n",
       "154  2019   cyano         0.40800        0.0        1.0                  0.80   \n",
       "155  2019      TP        22.60000        0.0       29.5                  0.96   \n",
       "\n",
       "     prob_above_threshold  \n",
       "0                     NaN  \n",
       "1                     NaN  \n",
       "2                     NaN  \n",
       "3                     NaN  \n",
       "4                     NaN  \n",
       "..                    ...  \n",
       "151                  0.22  \n",
       "152                  0.05  \n",
       "153                  0.12  \n",
       "154                  0.20  \n",
       "155                  0.04  \n",
       "\n",
       "[156 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if run_operational == True:\n",
    "    \n",
    "    # Re-generate era5-av predictions, using the operational predict function, which returns ever-so-slightly\n",
    "    # different results (not sure why - to investigate later...)\n",
    "    if met_evidence !='s5':\n",
    "    \n",
    "        # Sort out filepaths for the evidence data to read in and the output file\n",
    "        if run_mode == 'NextSeason':\n",
    "            ev_fname = 'DataForPrediction_GBN_%s_%s.csv' %(met_evidence, target_yr)\n",
    "            out_fname = 'GBN_prediction_operational_%s_%s.csv' %(met_evidence, target_yr)\n",
    "        else:\n",
    "            ev_fname = 'DataForPrediction_GBN_%s_%s-%s.csv' %(met_evidence, st_end_yr_dict[met_evidence][0], st_end_yr_dict[met_evidence][1])\n",
    "            out_fname = 'GBN_prediction_operational_%s_%s-%s.csv' %(met_evidence, st_end_yr_dict[met_evidence][0], st_end_yr_dict[met_evidence][1])\n",
    "\n",
    "        ev_path = os.path.join(ev_folder, ev_fname)\n",
    "        out_path = os.path.join(out_folder, out_fname)\n",
    "\n",
    "        # Read in evidence\n",
    "        ev_df = pd.read_csv(ev_path)\n",
    "\n",
    "        # Predict and save to csv\n",
    "        df = bn_predict_multipleyears_operational(rfile_fpath, ev_df)\n",
    "        df.to_csv(out_path, index=False)\n",
    "\n",
    "#         display(df)        \n",
    "        \n",
    "        # Take TP, colour and cyano predictions produced above using the 'deterministic' met data (era5-av in this case)\n",
    "        # Replace chl-a predictions with the naive seasonal forecast\n",
    "        sim_naive_chla = sim_naive.loc[sim_naive['node']=='chla']\n",
    "        df_operational = df.drop(df.loc[df['node']=='chla'].index)\n",
    "\n",
    "        df_operational = sim_naive_chla.set_index(['year','node']).append(df_operational.set_index(['year','node']), sort=False)\n",
    "        df_operational = df_operational.reset_index()\n",
    "        df_operational.loc[df_operational['node']=='chla','threshold'] = boundaries_dict['chla']\n",
    "\n",
    "        # Save to csv\n",
    "        if run_mode == 'NextSeason':\n",
    "            out_fname = 'Prediction_operational_%s.csv' %(target_yr)\n",
    "        else:\n",
    "            out_fname = 'Prediction_operational_%s-%s.csv' %(st_end_yr_dict[met_evidence][0], st_end_yr_dict[met_evidence][1])\n",
    "        out_path = os.path.join(out_folder, out_fname)\n",
    "\n",
    "        df_operational.to_csv(out_path, index=False)\n",
    "\n",
    "        display(df_operational)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
