{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(java.parameters = \"-Xmx100000m\")\n",
    "# Load packages. \n",
    "library(loadeR)\n",
    "library(transformeR)\n",
    "library(loadeR.ECOMS)\n",
    "library(visualizeR)\n",
    "library(convertR)\n",
    "library(drought4R)\n",
    "library(downscaleR)\n",
    "\n",
    "# Case Study:\n",
    "# caseStudy={'Lake Arreskov','Denmark',55.16,10.31,'sub-daily','both';...\n",
    "#   'Wupper Reservoir','Germany',51.1983,7.3011,'hourly or daily','both';...\n",
    "#   'Burrishoole Catchment','Ireland',[53.8833 54.05],[-9.6833 -9.4833],'Daily','both';...\n",
    "#   'Vansjo Catchment','Norway',[59.31 59.90],[10.63 11.25],'Daily','both';...\n",
    "#   'Sau Reservoir','Spain',41.9702,2.3994,'Daily or sub-daily','both';...\n",
    "#   'Mt. Bold Reservoir','Australia',[-35.15 -35.0167],[138.6667 138.8167],'6-hourly','both'};\n",
    "####################################################################################################\n",
    "## Example of Data Reference Sintax: How to build the directory structure and file naming         ##\n",
    "## considering observations, reanalysis, seasonal forecast or climate change projections          ##\n",
    "## SEE the proposal for the WATExR Archive Design in:                                             ## \n",
    "## https://docs.google.com/document/d/1yzNtw9W_z_ziPQ6GrnSgD9ov5O1swnohndDTAWOgpwc/edit           ##\n",
    "####################################################################################################\n",
    "#   Lake (lake_id): Is an identifier for the lake/case study.\n",
    "#   institution (institute_id): Is an identifier for the institution that is responsible for the scientific aspects of the simulation.\n",
    "#   LakeModelName (driving_lake_model_id): is an identifier of the driving lake model.\n",
    "#     The name consists of an institute identifier and a lake model identifier. \n",
    "#     The two parts of the name are separated by a '-' (dash). Note that dashes in either of the two parts are allowed. \n",
    "#   ClimateModelName (driving_climate_model_id) is an identifier of the driving climate model.\n",
    "#     The name consists of an institute identifier and a climate model identifier. \n",
    "#     The two parts of the name are separated by a '-' (dash). Note that dashes in either of the two parts are allowed.\n",
    "#     For observations or reanalysis indicate the name of the data set as model identifier. \n",
    "#   ExperimentName (driving_experiment_name) is:\n",
    "# Climate change projection: either \"evaluation\" or the value of the CMIP5 experiment_id of the data used (\"historical\", \"rcp4.5\", \"rcp8.5\", etc)\n",
    "# Seasonal Forecasts: \"seasonal\"\n",
    "# Observed data: \"observations\"\n",
    "# Reanalysis: \"reanalysis\"\n",
    "#   EnsembleMember (driving_model_ensemble_member) identifies the ensemble member of the global climate model, seasonal or climate change, experiment that produced the forcing data.\n",
    "# Climate change: the format should be the same used in the CMIP5 (e.g. r1i1p1)\n",
    "# Seasonal Forecasts: this element is defined by the member (e.g. member01 for the first member).\n",
    "# Reanalysis: Set this element as member01 for reanalysis data.\n",
    "#   Frequency (frequency) is the output frequency indicator: 6hr=6 hourly, day=daily, etc.\n",
    "#   StartTime and EndTime indicate the time span of the file content. The format is YYYY[MM[DD[HH[MM]]]], i.e. the year is represented by 4 digits, \n",
    "# while the month, day, hour, and minutes are represented by exactly 2 digits, if they are present at all. In accordance with CMIP5, only those \n",
    "# digits have to be included that are necessary to indicate the file content. The two dates are separated by a dash. All time stamps refer to UTC.2.2 \n",
    "##################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### GENERAL SETTINGS THAT NEED TO BE DEFINED IN EACH CASE STUDY ---------------------------------\n",
    "\n",
    "# Output path where the data will be saved (change to your local path).\n",
    "dir.data <- './data/' \n",
    "dir.Rdata <- './Rdata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the geographical domain\n",
    "lonLim <- c(8, 13) \n",
    "latLim <- c(57, 62)\n",
    "\n",
    "# Define the period and the season\n",
    "years <- 1979:2019\n",
    "season <- 1:12 #Full year\n",
    "\n",
    "# Location of the lake\n",
    "lake <- list(x= 10.7438771059,  y= 59.4392814052 )\n",
    "lakename <- 'Vansjo'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-11-13 14:08:10] Setting credentials...\n",
      "[2019-11-13 14:08:11] Success!\n",
      "Go to <http://www.meteo.unican.es/udg-tap/home> for details on your authorized groups and datasets\n",
      "[2019-11-13 14:08:13] Doing inventory ...\n",
      "[2019-11-13 14:13:04] Retrieving info for 'rsds' (15 vars remaining)\n",
      "[2019-11-13 14:13:05] Retrieving info for 'rlds' (14 vars remaining)\n",
      "[2019-11-13 14:13:05] Retrieving info for 'ssr' (13 vars remaining)\n",
      "[2019-11-13 14:13:05] Retrieving info for 'str' (12 vars remaining)\n",
      "[2019-11-13 14:13:05] Retrieving info for 'tsr' (11 vars remaining)\n",
      "[2019-11-13 14:13:05] Retrieving info for 'ttr' (10 vars remaining)\n",
      "[2019-11-13 14:13:05] Retrieving info for 'evaporation' (9 vars remaining)\n",
      "[2019-11-13 14:13:06] Retrieving info for 'pr' (8 vars remaining)\n",
      "[2019-11-13 14:13:06] Retrieving info for 'sst' (7 vars remaining)\n",
      "[2019-11-13 14:13:06] Retrieving info for 'ps' (6 vars remaining)\n",
      "[2019-11-13 14:13:06] Retrieving info for 'psl' (5 vars remaining)\n",
      "[2019-11-13 14:13:06] Retrieving info for 'tcc' (4 vars remaining)\n",
      "[2019-11-13 14:13:06] Retrieving info for 'uas' (3 vars remaining)\n",
      "[2019-11-13 14:13:06] Retrieving info for 'vas' (2 vars remaining)\n",
      "[2019-11-13 14:13:06] Retrieving info for 'tas' (1 vars remaining)\n",
      "[2019-11-13 14:13:07] Retrieving info for 'tdps' (0 vars remaining)\n",
      "[2019-11-13 14:13:07] Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'rsds'</li>\n",
       "\t<li>'rlds'</li>\n",
       "\t<li>'ssr'</li>\n",
       "\t<li>'str'</li>\n",
       "\t<li>'tsr'</li>\n",
       "\t<li>'ttr'</li>\n",
       "\t<li>'evaporation'</li>\n",
       "\t<li>'pr'</li>\n",
       "\t<li>'sst'</li>\n",
       "\t<li>'ps'</li>\n",
       "\t<li>'psl'</li>\n",
       "\t<li>'tcc'</li>\n",
       "\t<li>'uas'</li>\n",
       "\t<li>'vas'</li>\n",
       "\t<li>'tas'</li>\n",
       "\t<li>'tdps'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'rsds'\n",
       "\\item 'rlds'\n",
       "\\item 'ssr'\n",
       "\\item 'str'\n",
       "\\item 'tsr'\n",
       "\\item 'ttr'\n",
       "\\item 'evaporation'\n",
       "\\item 'pr'\n",
       "\\item 'sst'\n",
       "\\item 'ps'\n",
       "\\item 'psl'\n",
       "\\item 'tcc'\n",
       "\\item 'uas'\n",
       "\\item 'vas'\n",
       "\\item 'tas'\n",
       "\\item 'tdps'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'rsds'\n",
       "2. 'rlds'\n",
       "3. 'ssr'\n",
       "4. 'str'\n",
       "5. 'tsr'\n",
       "6. 'ttr'\n",
       "7. 'evaporation'\n",
       "8. 'pr'\n",
       "9. 'sst'\n",
       "10. 'ps'\n",
       "11. 'psl'\n",
       "12. 'tcc'\n",
       "13. 'uas'\n",
       "14. 'vas'\n",
       "15. 'tas'\n",
       "16. 'tdps'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"rsds\"        \"rlds\"        \"ssr\"         \"str\"         \"tsr\"        \n",
       " [6] \"ttr\"         \"evaporation\" \"pr\"          \"sst\"         \"ps\"         \n",
       "[11] \"psl\"         \"tcc\"         \"uas\"         \"vas\"         \"tas\"        \n",
       "[16] \"tdps\"       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the dataset \n",
    "## dataset <- \"ECMWF_ERA-Interim-ESD\"\n",
    "dataset <- \"http://meteo.unican.es/tds5/dodsC/interim/interim075_WATExR.ncml\"\n",
    "\n",
    "# Login in the TAP-UDG the climate4R libraries \n",
    "# More details about UDG in https://doi.org/10.1016/j.cliser.2017.07.001\n",
    "loginUDG(\"WATExR\", \"1234567890\")\n",
    "\n",
    "# Check available variables in the dataset (EWEMBI)  \n",
    "di <- dataInventory(dataset)\n",
    "names(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uas    vas     ps    tas     pr   rsds   rlds   hurs     cc \n",
      " \"uas\"  \"vas\"   \"ps\"  \"tas\"   \"pr\" \"rsds\" \"rlds\" \"hurs\"   \"cc\" \n"
     ]
    }
   ],
   "source": [
    "#Loading the observational (ewembi) data\n",
    "dir.Rdata.obs <- \"/home/jovyan/WATExR/Norway_Morsa/Data/Meteorological/RData/PIK_Obs-EWEMBI_1_2_3_4_5_6_7_8_9_10_11_12_uas_vas_ps_tas_pr_rsds_rlds_hurs_petH.rda\"\n",
    "\n",
    "obs.data <- get(load(dir.Rdata.obs))\n",
    "varnames.obs <- sapply(obs.data, function(x) getVarNames(x)) # to check the variables in the observational data.\n",
    "print(varnames.obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-14 20:26:18] Opening dataset...\n",
      "[2019-10-14 20:26:20] The dataset was successfuly opened\n",
      "[2019-10-14 20:26:20] Defining geo-location parameters\n",
      "[2019-10-14 20:26:20] Defining time selection parameters\n",
      "NOTE: Daily aggregation will be computed from 6-hourly data\n",
      "[2019-10-14 20:26:22] Retrieving data subset ...\n",
      "[2019-10-14 20:27:26] Done\n",
      "[2019-10-14 20:27:26] Opening dataset...\n",
      "[2019-10-14 20:27:28] The dataset was successfuly opened\n",
      "[2019-10-14 20:27:28] Defining geo-location parameters\n",
      "[2019-10-14 20:27:28] Defining time selection parameters\n",
      "NOTE: Daily aggregation will be computed from 6-hourly data\n",
      "[2019-10-14 20:27:31] Retrieving data subset ...\n",
      "[2019-10-14 20:28:50] Done\n",
      "[2019-10-14 20:28:50] Opening dataset...\n",
      "[2019-10-14 20:28:52] The dataset was successfuly opened\n",
      "[2019-10-14 20:28:52] Defining geo-location parameters\n",
      "[2019-10-14 20:28:52] Defining time selection parameters\n",
      "NOTE: Daily aggregation will be computed from 6-hourly data\n",
      "[2019-10-14 20:28:56] Retrieving data subset ...\n",
      "[2019-10-14 20:30:55] Done\n",
      "[2019-10-14 20:30:55] Opening dataset...\n",
      "[2019-10-14 20:30:57] The dataset was successfuly opened\n",
      "[2019-10-14 20:30:57] Defining geo-location parameters\n",
      "[2019-10-14 20:30:58] Defining time selection parameters\n",
      "NOTE: Daily aggregation will be computed from 6-hourly data\n",
      "[2019-10-14 20:31:02] Retrieving data subset ...\n"
     ]
    }
   ],
   "source": [
    "variables <- c(\"uas\", \"vas\", \"ps\", \"tas\", \"pr\", \"rsds\", \"rlds\")\n",
    "# Define daily aggregation function for each variable selected. \n",
    "aggr.fun <- c(\"mean\", \"mean\", \"mean\", \"mean\", \"sum\", \"mean\", \"mean\")\n",
    "########## DATA LOADING AND TRANSFORMATION ----------------------------------------------------------\n",
    "# Load reanalysis (ERA-Interim) with function loadGridData from package loadeR.\n",
    "# Data is loaded in a loop (function lapply) to load all variables in a single code line.\n",
    "# A list of grids is obtained, each slot in the list corresponds to a variable\n",
    "data.prelim <- lapply(1:length(variables), function(x) loadGridData(dataset, var = variables[x], years = years, \n",
    "                                                                    lonLim = lonLim, latLim = latLim, season = season, \n",
    "                                                                    time = \"DD\", aggr.d = aggr.fun[x]))\n",
    "\n",
    "# Deal with the special case of accumulated variables (get temporal intersection)\n",
    "data.prelim <- intersectGrid(data.prelim, type = \"temporal\", which.return = 1:length(variables))\n",
    "names(data.prelim) <- c(\"uas\", \"vas\", \"ps\", \"tas\", \"pr\", \"rsds\", \"rlds\")\n",
    "\n",
    "# Compute relative humidity from the mean temperature and the dew point with function tdps2hurs from package convertR\n",
    "tdps <- loadGridData(dataset, var = \"tdps\", years = years, \n",
    "                     lonLim = lonLim, latLim = latLim, \n",
    "                     season = season,  time = \"DD\", aggr.d = \"mean\")\n",
    "tdps <- intersectGrid(tdps, data.prelim$tas, which.return = 1)\n",
    "\n",
    "hurs <- data.prelim$tas # Predefine the object\n",
    "hurs$Data <- tdps2hurs(data.prelim$tas$Data, tdps$Data) # Assign the data matrix\n",
    "# Define correctly the metadata of the object:\n",
    "hurs$Variable$varName <- \"hurs\"\n",
    "attr(hurs$Variable,\"units\") <- \"%\"\n",
    "attr(hurs$Variable,\"description\") <- \"2 metre relative humidity\"\n",
    "attr(hurs$Variable,\"longname\") <- \"hurs\"\n",
    "# Include variables in data.prelim\n",
    "data.prelim <- c(data.prelim, \"hurs\" = list(hurs))\n",
    "\n",
    "# Compute wss\n",
    "wss <- data.prelim$uas\n",
    "wss$Data <- data.prelim$uas$Data^2 + data.prelim$vas$Data^2\n",
    "# Define correctly the metadata of the object:\n",
    "wss$Variable$varName <- \"wss\"\n",
    "attr(wss$Variable,\"units\") <- \"m s**-1\"\n",
    "attr(wss$Variable,\"description\") <- \"Near-Surface Wind Speed\"\n",
    "attr(wss$Variable,\"longname\") <- \"wss\"\n",
    "# Include variables in data.prelim\n",
    "data.prelim <- c(data.prelim, \"wss\" = list(wss))\n",
    "\n",
    "# Bilinear interpolation of the data to the location of the lake. See ?interpGrid for other methods.\n",
    "data.interp <- lapply(data.prelim, function(x) interpGrid(x, new.coordinates = lake, \n",
    "                                                          method = \"bilinear\", \n",
    "                                                          bilin.method = \"akima\"))\n",
    "\n",
    "# Convert pressure and temperature units to millibars and celsius with function udConvertGrid from package convertR.\n",
    "data.interp$ps <- udConvertGrid(data.interp$ps, new.units = \"millibars\") #No need SWAT\n",
    "data.interp$tas <- udConvertGrid(data.interp$tas, new.units = \"celsius\")\n",
    "#data.interp$tasmax <- udConvertGrid(data.interp$tasmax, new.units = \"celsius\")\n",
    "#data.interp$tasmin <- udConvertGrid(data.interp$tasmin, new.units = \"celsius\")\n",
    "\n",
    "# Convert radiation units from J/m2/12hours to W/m2\n",
    "data.interp$rsds$Data <- data.interp$rsds$Data/43200 \n",
    "attr(data.interp$rsds$Variable,\"units\") <- \"W.m-2\"\n",
    "data.interp$rlds$Data <- data.interp$rlds$Data/43200 \n",
    "attr(data.interp$rlds$Variable,\"units\") <- \"W.m-2\"\n",
    "\n",
    "#Convert relative humidity units to fractions with function udConvertGrid from package convertR.\n",
    "#data.interp$hurs <- udConvertGrid(data.interp$hurs, new.units = \"\")\n",
    "\n",
    "#Convert shortwave radiation units to MJ/(m2*day) with function udConvertGrid from package convertR.\n",
    "#data.interp$rsds <- udConvertGrid(data.interp$rsds, new.units = \"MJ m-2 day-1\")\n",
    "#data.interp$rlds <- udConvertGrid(data.interp$rlds, new.units = \"MJ m-2 day-1\")\n",
    "\n",
    "# Compute cloud cover with function rad2cc\n",
    "clt <- redim(rad2cc(rsds = data.interp$rsds, rlds = data.interp$rlds), drop = TRUE)\n",
    "clt$Variable$varName <- \"cc\"\n",
    "\n",
    "# Put all variables together\n",
    "data <- c(data.interp, \"cc\" = list(clt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"rlist\")\n",
    "library(\"rlist\")\n",
    "list.save(data, \"erainterim_noconvert.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variable consistency\n",
    "if (!all(names(obs.data) %in% names(data))) stop(\"variables in obs.data and data (seasonal forecast) do not match.\")\n",
    "\n",
    "# #order variables\n",
    "data <- data[match(names(obs.data), names(data))]\n",
    "varnames <- names(data)\n",
    "\n",
    "##### BIAS CORRECTION -----------------------------------------------------------------------\n",
    "# Subset observational data to the same dates as forecast data\n",
    "obs.data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 1)})\n",
    "data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 2)})\n",
    "names(obs.data) <- varnames\n",
    "names(data) <- varnames\n",
    "\n",
    "# Collect some common metadata (e.g. from variable uas)\n",
    "dates <- data[[1]]$Dates\n",
    "xycoords <- getCoordinates(data[[1]])\n",
    "\n",
    "# Bias correction with leave-one-year-out (\"loo\") cross-validation\n",
    "# type ?biasCorrection in R for more info about the parameter settings for bias correction.\n",
    "data.bc.cross <- lapply(1:length(data), function(x)  {\n",
    "  precip <- FALSE\n",
    "  if (names(data)[x] == \"pr\") precip <- TRUE\n",
    "  biasCorrection(y = obs.data[[x]], x = data[[x]], \n",
    "                 method = \"eqm\", cross.val = \"loo\",\n",
    "                 precipitation = precip,\n",
    "                 wet.threshold = 1,\n",
    "                 window = c(90, 31),\n",
    "                 join.members = TRUE)\n",
    "}) \n",
    "names(data.bc.cross) <- varnames\n",
    "# Bias correction without cross-validation\n",
    "data.bc <- lapply(1:length(data), function(v)  {\n",
    "  pre <- FALSE\n",
    "  print(names(data)[v])\n",
    "  if (names(data)[v] == \"pr\") pre <- TRUE\n",
    "  biasCorrection(y = obs.data[[v]], x = data[[v]], \n",
    "                 method = \"eqm\",\n",
    "                 precipitation = pre,\n",
    "                 wet.threshold = 1,\n",
    "                 window = c(90, 31),\n",
    "                 join.members = TRUE)\n",
    "}) \n",
    "names(data.bc) <- varnames\n",
    "\n",
    "\n",
    "# save Rdata (*.rda file)\n",
    "save(data, file = paste0(dir.Rdata, \"interim075_WATExR_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_raw.rda\"))\n",
    "save(data.bc.cross, file = paste0(dir.Rdata, \"interim075_WATExR_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BCcross.rda\"))\n",
    "save(data.bc, file = paste0(dir.Rdata, \"interim075_WATExR_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BC.rda\"))\n",
    "\n",
    "list.save(data, \"erainterim_bias_raw.rds\")\n",
    "list.save(data.bc.cross, \"erainterim_bias_bc_cross.rds\")\n",
    "list.save(data.bc, \"erainterim_bias_bc.rds\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ########## BUILD FINAL DATA --------------------------------------------------------------\n",
    "\n",
    "# datatoexport <- data.bc\n",
    "\n",
    "# # extract the data arrays of all variables from the list\n",
    "# data <- lapply(datatoexport, function(x) x[[\"Data\"]])\n",
    "\n",
    "# # Remove unwanted variables from output\n",
    "# data[\"rsds\"] <- NULL \n",
    "# data[\"rlds\"] <- NULL\n",
    "# # Build data frame\n",
    "# yymmdd <- as.Date(dates$start)\n",
    "# hhmmss <- format(as.POSIXlt(dates$start), format = \"%H:%M:%S\") \n",
    "# df <- data.frame(c(list(\"dates1\" = yymmdd, \"dates2\" = hhmmss)), data)\n",
    "\n",
    "\n",
    "# ########### EXPORT DATA ACCORDING TO THE WATExR ARCHIVE DESIGN -----------------------------\n",
    "# ## SEE the proposal for the WATExR Archive Design in:                                            \n",
    "# ## https://docs.google.com/document/d/1yzNtw9W_z_ziPQ6GrnSgD9ov5O1swnohndDTAWOgpwc/edit\n",
    "\n",
    "# # Define metadata to generate the file name\n",
    "# institution <- \"UC\"\n",
    "# lake_id <- lakename\n",
    "# ClimateModelName <- \"ERA-Interim\"\n",
    "# ExperimentName <- \"reanalysis\"\n",
    "# member <- \"member01\"\n",
    "# freq <- \"day\"\n",
    "\n",
    "# # Create directory and save file\n",
    "# startTime <- format(as.POSIXlt(yymmdd[1]), format = \"%Y%m%d\")\n",
    "# endTime <- format(tail(as.POSIXlt(yymmdd), n = 1), format = \"%Y%m%d\")\n",
    "# dirName <- paste0(dir.data, lake_id, \"/CLIMATE/\", lake_id, \"_\", institution, \"_\", ClimateModelName, \"_\", ExperimentName, \"_\", member, \"_\", freq, \"_\", startTime, \"-\", endTime, \"/\", sep = \"\", collapse = NULL)\n",
    "# dir.create(dirName, showWarnings = TRUE, recursive = TRUE, mode = \"0777\")\n",
    "# write.table(df, paste0(dirName,\"meteo_file.dat\", sep = \"\", collapse = NULL), sep = \"\\t\", row.names = FALSE, col.names = FALSE, quote = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
