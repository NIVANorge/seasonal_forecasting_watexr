{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: rJava\n",
      "Loading required package: loadeR.java\n",
      "Java version 1.8x amd64 by Azul Systems, Inc. detected\n",
      "NetCDF Java Library v4.6.0-SNAPSHOT (23 Apr 2015) loaded and ready\n",
      "loadeR version 1.4.15 (2019-07-30) is loaded\n",
      "Please use 'citation(\"loadeR\")' to cite this package.\n",
      "transformeR version 1.5.1 (2019-07-13) is loaded\n",
      "WARNING: Your current version of transformeR (v1.5.1) is not up-to-date\n",
      "Get the latest stable version (1.6.0) using <devtools::install_github('SantanderMetGroup/transformeR')>\n",
      "Please see 'citation(\"transformeR\")' to cite this package.\n",
      "loadeR.ECOMS version 1.4.6 (2018-10-20) is loaded\n",
      "Please use 'citation(\"loadeR.ECOMS\")' to cite this package.\n",
      "Warning message:\n",
      "“no DISPLAY variable so Tk is not available”visualizeR version 1.4.0 (2019-07-09) is loaded\n",
      "WARNING: Your current version of visualizeR (v1.4.0) is not up-to-date\n",
      "Get the latest stable version (1.5.0) using <devtools::install_github('SantanderMetGroup/visualizeR')>\n",
      "Please see 'citation(\"visualizeR\")' to cite this package.\n",
      "Loading required package: udunits2\n",
      "udunits system database read from /opt/conda/lib/R/library/udunits2/share/udunits2.xml\n",
      "convertR version 0.1.2 (2018-06-28) is loaded\n",
      "  More information about the 'climate4R' ecosystem in: http://meteo.unican.es/climate4R\n",
      "\n",
      "Attaching package: ‘convertR’\n",
      "\n",
      "The following objects are masked from ‘package:loadeR’:\n",
      "\n",
      "    hurs2huss, huss2hurs\n",
      "\n",
      "drought4R version 0.2.0 (2019-04-24) is loaded\n"
     ]
    }
   ],
   "source": [
    "options(java.parameters = \"-Xmx100000m\")\n",
    "# Load packages. \n",
    "library(loadeR)\n",
    "library(transformeR)\n",
    "library(loadeR.ECOMS)\n",
    "library(visualizeR)\n",
    "library(convertR)\n",
    "library(drought4R)\n",
    "\n",
    "# Case Study:\n",
    "# caseStudy={'Lake Arreskov','Denmark',55.16,10.31,'sub-daily','both';...\n",
    "#   'Wupper Reservoir','Germany',51.1983,7.3011,'hourly or daily','both';...\n",
    "#   'Burrishoole Catchment','Ireland',[53.8833 54.05],[-9.6833 -9.4833],'Daily','both';...\n",
    "#   'Vansjo Catchment','Norway',[59.31 59.90],[10.63 11.25],'Daily','both';...\n",
    "#   'Sau Reservoir','Spain',41.9702,2.3994,'Daily or sub-daily','both';...\n",
    "#   'Mt. Bold Reservoir','Australia',[-35.15 -35.0167],[138.6667 138.8167],'6-hourly','both'};\n",
    "####################################################################################################\n",
    "## Example of Data Reference Sintax: How to build the directory structure and file naming         ##\n",
    "## considering observations, reanalysis, seasonal forecast or climate change projections          ##\n",
    "## SEE the proposal for the WATExR Archive Design in:                                             ## \n",
    "## https://docs.google.com/document/d/1yzNtw9W_z_ziPQ6GrnSgD9ov5O1swnohndDTAWOgpwc/edit           ##\n",
    "####################################################################################################\n",
    "#   Lake (lake_id): Is an identifier for the lake/case study.\n",
    "#   institution (institute_id): Is an identifier for the institution that is responsible for the scientific aspects of the simulation.\n",
    "#   LakeModelName (driving_lake_model_id): is an identifier of the driving lake model.\n",
    "#     The name consists of an institute identifier and a lake model identifier. \n",
    "#     The two parts of the name are separated by a '-' (dash). Note that dashes in either of the two parts are allowed. \n",
    "#   ClimateModelName (driving_climate_model_id) is an identifier of the driving climate model.\n",
    "#     The name consists of an institute identifier and a climate model identifier. \n",
    "#     The two parts of the name are separated by a '-' (dash). Note that dashes in either of the two parts are allowed.\n",
    "#     For observations or reanalysis indicate the name of the data set as model identifier. \n",
    "#   ExperimentName (driving_experiment_name) is:\n",
    "# Climate change projection: either \"evaluation\" or the value of the CMIP5 experiment_id of the data used (\"historical\", \"rcp4.5\", \"rcp8.5\", etc)\n",
    "# Seasonal Forecasts: \"seasonal\"\n",
    "# Observed data: \"observations\"\n",
    "# Reanalysis: \"reanalysis\"\n",
    "#   EnsembleMember (driving_model_ensemble_member) identifies the ensemble member of the global climate model, seasonal or climate change, experiment that produced the forcing data.\n",
    "# Climate change: the format should be the same used in the CMIP5 (e.g. r1i1p1)\n",
    "# Seasonal Forecasts: this element is defined by the member (e.g. member01 for the first member).\n",
    "# Reanalysis: Set this element as member01 for reanalysis data.\n",
    "#   Frequency (frequency) is the output frequency indicator: 6hr=6 hourly, day=daily, etc.\n",
    "#   StartTime and EndTime indicate the time span of the file content. The format is YYYY[MM[DD[HH[MM]]]], i.e. the year is represented by 4 digits, \n",
    "# while the month, day, hour, and minutes are represented by exactly 2 digits, if they are present at all. In accordance with CMIP5, only those \n",
    "# digits have to be included that are necessary to indicate the file content. The two dates are separated by a dash. All time stamps refer to UTC.2.2 \n",
    "##################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### GENERAL SETTINGS THAT NEED TO BE DEFINED IN EACH CASE STUDY ---------------------------------\n",
    "\n",
    "# Output path where the data will be saved (change to your local path).\n",
    "dir.data <- './data/' \n",
    "dir.Rdata <- './Rdata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the geographical domain\n",
    "lonLim <- c(8, 13) \n",
    "latLim <- c(57, 62)\n",
    "\n",
    "# Define the period and the season\n",
    "years <- 1979:2019\n",
    "season <- 1:12 #Full year\n",
    "\n",
    "# Location of the lake\n",
    "lake <- list(x= 10.7438771059,  y= 59.4392814052 )\n",
    "lakename <- 'Vansjo'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-10 08:30:30] Setting credentials...\n",
      "[2019-10-10 08:30:31] Success!\n",
      "Go to <http://www.meteo.unican.es/udg-tap/home> for details on your authorized groups and datasets\n",
      "[2019-10-10 08:30:31] Doing inventory ...\n",
      "[2019-10-10 08:30:36] Retrieving info for 'rsds' (15 vars remaining)\n",
      "[2019-10-10 08:30:36] Retrieving info for 'rlds' (14 vars remaining)\n",
      "[2019-10-10 08:30:36] Retrieving info for 'ssr' (13 vars remaining)\n",
      "[2019-10-10 08:30:36] Retrieving info for 'str' (12 vars remaining)\n",
      "[2019-10-10 08:30:37] Retrieving info for 'tsr' (11 vars remaining)\n",
      "[2019-10-10 08:30:37] Retrieving info for 'ttr' (10 vars remaining)\n",
      "[2019-10-10 08:30:37] Retrieving info for 'evaporation' (9 vars remaining)\n",
      "[2019-10-10 08:30:37] Retrieving info for 'pr' (8 vars remaining)\n",
      "[2019-10-10 08:30:37] Retrieving info for 'sst' (7 vars remaining)\n",
      "[2019-10-10 08:30:37] Retrieving info for 'ps' (6 vars remaining)\n",
      "[2019-10-10 08:30:37] Retrieving info for 'psl' (5 vars remaining)\n",
      "[2019-10-10 08:30:37] Retrieving info for 'tcc' (4 vars remaining)\n",
      "[2019-10-10 08:30:37] Retrieving info for 'uas' (3 vars remaining)\n",
      "[2019-10-10 08:30:37] Retrieving info for 'vas' (2 vars remaining)\n",
      "[2019-10-10 08:30:37] Retrieving info for 'tas' (1 vars remaining)\n",
      "[2019-10-10 08:30:38] Retrieving info for 'tdps' (0 vars remaining)\n",
      "[2019-10-10 08:30:38] Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'rsds'</li>\n",
       "\t<li>'rlds'</li>\n",
       "\t<li>'ssr'</li>\n",
       "\t<li>'str'</li>\n",
       "\t<li>'tsr'</li>\n",
       "\t<li>'ttr'</li>\n",
       "\t<li>'evaporation'</li>\n",
       "\t<li>'pr'</li>\n",
       "\t<li>'sst'</li>\n",
       "\t<li>'ps'</li>\n",
       "\t<li>'psl'</li>\n",
       "\t<li>'tcc'</li>\n",
       "\t<li>'uas'</li>\n",
       "\t<li>'vas'</li>\n",
       "\t<li>'tas'</li>\n",
       "\t<li>'tdps'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'rsds'\n",
       "\\item 'rlds'\n",
       "\\item 'ssr'\n",
       "\\item 'str'\n",
       "\\item 'tsr'\n",
       "\\item 'ttr'\n",
       "\\item 'evaporation'\n",
       "\\item 'pr'\n",
       "\\item 'sst'\n",
       "\\item 'ps'\n",
       "\\item 'psl'\n",
       "\\item 'tcc'\n",
       "\\item 'uas'\n",
       "\\item 'vas'\n",
       "\\item 'tas'\n",
       "\\item 'tdps'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'rsds'\n",
       "2. 'rlds'\n",
       "3. 'ssr'\n",
       "4. 'str'\n",
       "5. 'tsr'\n",
       "6. 'ttr'\n",
       "7. 'evaporation'\n",
       "8. 'pr'\n",
       "9. 'sst'\n",
       "10. 'ps'\n",
       "11. 'psl'\n",
       "12. 'tcc'\n",
       "13. 'uas'\n",
       "14. 'vas'\n",
       "15. 'tas'\n",
       "16. 'tdps'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"rsds\"        \"rlds\"        \"ssr\"         \"str\"         \"tsr\"        \n",
       " [6] \"ttr\"         \"evaporation\" \"pr\"          \"sst\"         \"ps\"         \n",
       "[11] \"psl\"         \"tcc\"         \"uas\"         \"vas\"         \"tas\"        \n",
       "[16] \"tdps\"       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the dataset \n",
    "## dataset <- \"ECMWF_ERA-Interim-ESD\"\n",
    "dataset <- \"http://meteo.unican.es/tds5/dodsC/interim/interim075_WATExR.ncml\"\n",
    "\n",
    "# Login in the TAP-UDG the climate4R libraries \n",
    "# More details about UDG in https://doi.org/10.1016/j.cliser.2017.07.001\n",
    "loginUDG(\"WATExR\", \"1234567890\")\n",
    "\n",
    "# Check available variables in the dataset (EWEMBI)  \n",
    "di <- dataInventory(dataset)\n",
    "names(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-10 08:30:38] Opening dataset...\n",
      "[2019-10-10 08:30:42] The dataset was successfuly opened\n",
      "[2019-10-10 08:30:42] Defining geo-location parameters\n",
      "[2019-10-10 08:30:42] Defining time selection parameters\n",
      "NOTE: Daily aggregation will be computed from 6-hourly data\n",
      "[2019-10-10 08:30:42] Retrieving data subset ...\n",
      "[2019-10-10 08:34:10] Done\n",
      "[2019-10-10 08:34:10] Opening dataset...\n",
      "[2019-10-10 08:34:14] The dataset was successfuly opened\n",
      "[2019-10-10 08:34:14] Defining geo-location parameters\n",
      "[2019-10-10 08:34:14] Defining time selection parameters\n",
      "NOTE: Daily aggregation will be computed from 6-hourly data\n",
      "[2019-10-10 08:34:15] Retrieving data subset ...\n",
      "[2019-10-10 08:38:21] Done\n",
      "[2019-10-10 08:38:21] Opening dataset...\n",
      "[2019-10-10 08:38:28] The dataset was successfuly opened\n",
      "[2019-10-10 08:38:28] Defining geo-location parameters\n",
      "[2019-10-10 08:38:28] Defining time selection parameters\n",
      "NOTE: Daily aggregation will be computed from 6-hourly data\n",
      "[2019-10-10 08:38:29] Retrieving data subset ...\n",
      "[2019-10-10 08:42:07] Done\n",
      "[2019-10-10 08:42:08] Opening dataset...\n",
      "[2019-10-10 08:42:11] The dataset was successfuly opened\n",
      "[2019-10-10 08:42:11] Defining geo-location parameters\n",
      "[2019-10-10 08:42:11] Defining time selection parameters\n",
      "NOTE: Daily aggregation will be computed from 6-hourly data\n",
      "[2019-10-10 08:42:12] Retrieving data subset ...\n",
      "[2019-10-10 08:48:24] Done\n",
      "[2019-10-10 08:48:25] Opening dataset...\n",
      "[2019-10-10 08:48:28] The dataset was successfuly opened\n",
      "[2019-10-10 08:48:28] Defining geo-location parameters\n",
      "[2019-10-10 08:48:28] Defining time selection parameters\n",
      "NOTE: Daily aggregation will be computed from 12-hourly data\n",
      "[2019-10-10 08:48:29] Retrieving data subset ...\n",
      "[2019-10-10 08:50:10] Done\n",
      "[2019-10-10 08:50:10] Opening dataset...\n",
      "[2019-10-10 08:50:13] The dataset was successfuly opened\n",
      "[2019-10-10 08:50:13] Defining geo-location parameters\n",
      "[2019-10-10 08:50:14] Defining time selection parameters\n",
      "NOTE: Daily aggregation will be computed from 12-hourly data\n",
      "[2019-10-10 08:50:14] Retrieving data subset ...\n",
      "[2019-10-10 08:52:15] Done\n",
      "[2019-10-10 08:52:16] Opening dataset...\n",
      "[2019-10-10 08:52:19] The dataset was successfuly opened\n",
      "[2019-10-10 08:52:19] Defining geo-location parameters\n",
      "[2019-10-10 08:52:19] Defining time selection parameters\n",
      "NOTE: Daily aggregation will be computed from 12-hourly data\n",
      "[2019-10-10 08:52:20] Retrieving data subset ...\n",
      "[2019-10-10 08:53:12] Done\n",
      "[2019-10-10 08:53:13] Opening dataset...\n",
      "[2019-10-10 08:53:17] The dataset was successfuly opened\n",
      "[2019-10-10 08:53:17] Defining geo-location parameters\n",
      "[2019-10-10 08:53:17] Defining time selection parameters\n",
      "NOTE: Daily aggregation will be computed from 6-hourly data\n",
      "[2019-10-10 08:53:17] Retrieving data subset ...\n",
      "[2019-10-10 09:13:07] Done\n",
      "NOTE: New coordinates are irregular, bilin.method = 'fields'\n",
      "[2019-10-10 09:13:08] Performing bilinear interpolation... may take a while\n",
      "[2019-10-10 09:13:20] Done\n",
      "NOTE: New coordinates are irregular, bilin.method = 'fields'\n",
      "[2019-10-10 09:13:20] Performing bilinear interpolation... may take a while\n",
      "[2019-10-10 09:13:33] Done\n",
      "NOTE: New coordinates are irregular, bilin.method = 'fields'\n",
      "[2019-10-10 09:13:33] Performing bilinear interpolation... may take a while\n",
      "[2019-10-10 09:13:49] Done\n",
      "NOTE: New coordinates are irregular, bilin.method = 'fields'\n",
      "[2019-10-10 09:13:49] Performing bilinear interpolation... may take a while\n",
      "[2019-10-10 09:14:06] Done\n",
      "NOTE: New coordinates are irregular, bilin.method = 'fields'\n",
      "[2019-10-10 09:14:06] Performing bilinear interpolation... may take a while\n",
      "[2019-10-10 09:14:19] Done\n",
      "NOTE: New coordinates are irregular, bilin.method = 'fields'\n",
      "[2019-10-10 09:14:19] Performing bilinear interpolation... may take a while\n",
      "[2019-10-10 09:14:31] Done\n",
      "NOTE: New coordinates are irregular, bilin.method = 'fields'\n",
      "[2019-10-10 09:14:31] Performing bilinear interpolation... may take a while\n",
      "[2019-10-10 09:14:43] Done\n",
      "NOTE: New coordinates are irregular, bilin.method = 'fields'\n",
      "[2019-10-10 09:14:44] Performing bilinear interpolation... may take a while\n",
      "[2019-10-10 09:14:54] Done\n",
      "NOTE: New coordinates are irregular, bilin.method = 'fields'\n",
      "[2019-10-10 09:14:54] Performing bilinear interpolation... may take a while\n",
      "[2019-10-10 09:15:10] Done\n",
      "[2019-10-10 09:15:10] Estimating cloud cover ...\n",
      "[2019-10-10 09:15:12] Done.\n"
     ]
    }
   ],
   "source": [
    "variables <- c(\"uas\", \"vas\", \"ps\", \"tas\", \"pr\", \"rsds\", \"rlds\")\n",
    "# Define daily aggregation function for each variable selected. \n",
    "aggr.fun <- c(\"mean\", \"mean\", \"mean\", \"mean\", \"sum\", \"mean\", \"mean\")\n",
    "########## DATA LOADING AND TRANSFORMATION ----------------------------------------------------------\n",
    "# Load reanalysis (ERA-Interim) with function loadGridData from package loadeR.\n",
    "# Data is loaded in a loop (function lapply) to load all variables in a single code line.\n",
    "# A list of grids is obtained, each slot in the list corresponds to a variable\n",
    "data.prelim <- lapply(1:length(variables), function(x) loadGridData(dataset, var = variables[x], years = years, \n",
    "                                                                    lonLim = lonLim, latLim = latLim, season = season, \n",
    "                                                                    time = \"DD\", aggr.d = aggr.fun[x]))\n",
    "\n",
    "# Deal with the special case of accumulated variables (get temporal intersection)\n",
    "data.prelim <- intersectGrid(data.prelim, type = \"temporal\", which.return = 1:length(variables))\n",
    "names(data.prelim) <- c(\"uas\", \"vas\", \"ps\", \"tas\", \"pr\", \"rsds\", \"rlds\")\n",
    "\n",
    "# Compute relative humidity from the mean temperature and the dew point with function tdps2hurs from package convertR\n",
    "tdps <- loadGridData(dataset, var = \"tdps\", years = years, \n",
    "                     lonLim = lonLim, latLim = latLim, \n",
    "                     season = season,  time = \"DD\", aggr.d = \"mean\")\n",
    "tdps <- intersectGrid(tdps, data.prelim$tas, which.return = 1)\n",
    "\n",
    "hurs <- data.prelim$tas # Predefine the object\n",
    "hurs$Data <- tdps2hurs(data.prelim$tas$Data, tdps$Data) # Assign the data matrix\n",
    "# Define correctly the metadata of the object:\n",
    "hurs$Variable$varName <- \"hurs\"\n",
    "attr(hurs$Variable,\"units\") <- \"%\"\n",
    "attr(hurs$Variable,\"description\") <- \"2 metre relative humidity\"\n",
    "attr(hurs$Variable,\"longname\") <- \"hurs\"\n",
    "# Include variables in data.prelim\n",
    "data.prelim <- c(data.prelim, \"hurs\" = list(hurs))\n",
    "\n",
    "# Compute wss\n",
    "wss <- data.prelim$uas\n",
    "wss$Data <- data.prelim$uas$Data^2 + data.prelim$vas$Data^2\n",
    "# Define correctly the metadata of the object:\n",
    "wss$Variable$varName <- \"wss\"\n",
    "attr(wss$Variable,\"units\") <- \"m s**-1\"\n",
    "attr(wss$Variable,\"description\") <- \"Near-Surface Wind Speed\"\n",
    "attr(wss$Variable,\"longname\") <- \"wss\"\n",
    "# Include variables in data.prelim\n",
    "data.prelim <- c(data.prelim, \"wss\" = list(wss))\n",
    "\n",
    "# Bilinear interpolation of the data to the location of the lake. See ?interpGrid for other methods.\n",
    "data.interp <- lapply(data.prelim, function(x) interpGrid(x, new.coordinates = lake, \n",
    "                                                          method = \"bilinear\", \n",
    "                                                          bilin.method = \"akima\"))\n",
    "\n",
    "# Convert pressure and temperature units to millibars and celsius with function udConvertGrid from package convertR.\n",
    "data.interp$ps <- udConvertGrid(data.interp$ps, new.units = \"millibars\") #No need SWAT\n",
    "data.interp$tas <- udConvertGrid(data.interp$tas, new.units = \"celsius\")\n",
    "#data.interp$tasmax <- udConvertGrid(data.interp$tasmax, new.units = \"celsius\")\n",
    "#data.interp$tasmin <- udConvertGrid(data.interp$tasmin, new.units = \"celsius\")\n",
    "\n",
    "# Convert radiation units from J/m2/12hours to W/m2\n",
    "data.interp$rsds$Data <- data.interp$rsds$Data/43200 \n",
    "attr(data.interp$rsds$Variable,\"units\") <- \"W.m-2\"\n",
    "data.interp$rlds$Data <- data.interp$rlds$Data/43200 \n",
    "attr(data.interp$rlds$Variable,\"units\") <- \"W.m-2\"\n",
    "\n",
    "#Convert relative humidity units to fractions with function udConvertGrid from package convertR.\n",
    "#data.interp$hurs <- udConvertGrid(data.interp$hurs, new.units = \"\")\n",
    "\n",
    "#Convert shortwave radiation units to MJ/(m2*day) with function udConvertGrid from package convertR.\n",
    "#data.interp$rsds <- udConvertGrid(data.interp$rsds, new.units = \"MJ m-2 day-1\")\n",
    "#data.interp$rlds <- udConvertGrid(data.interp$rlds, new.units = \"MJ m-2 day-1\")\n",
    "\n",
    "# Compute cloud cover with function rad2cc\n",
    "clt <- redim(rad2cc(rsds = data.interp$rsds, rlds = data.interp$rlds), drop = TRUE)\n",
    "clt$Variable$varName <- \"cc\"\n",
    "\n",
    "# Put all variables together\n",
    "data <- c(data.interp, \"cc\" = list(clt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"rlist\")\n",
    "library(\"rlist\")\n",
    "list.save(data, \"erainterim_noconvert.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variable consistency\n",
    "if (!all(names(obs.data) %in% names(data))) stop(\"variables in obs.data and data (seasonal forecast) do not match.\")\n",
    "\n",
    "#order variables\n",
    "data <- data[match(names(obs.data), names(data))]\n",
    "varnames <- names(data)\n",
    "\n",
    "##### BIAS CORRECTION -----------------------------------------------------------------------\n",
    "# Subset observational data to the same dates as forecast data\n",
    "obs.data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 1)})\n",
    "data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 2)})\n",
    "names(obs.data) <- varnames\n",
    "names(data) <- varnames\n",
    "\n",
    "# Collect some common metadata (e.g. from variable uas)\n",
    "dates <- data[[1]]$Dates\n",
    "xycoords <- getCoordinates(data[[1]])\n",
    "\n",
    "# Bias correction with leave-one-year-out (\"loo\") cross-validation\n",
    "# type ?biasCorrection in R for more info about the parameter settings for bias correction.\n",
    "data.bc.cross <- lapply(1:length(data), function(x)  {\n",
    "  precip <- FALSE\n",
    "  if (names(data)[x] == \"pr\") precip <- TRUE\n",
    "  biasCorrection(y = obs.data[[x]], x = data[[x]], \n",
    "                 method = \"eqm\", cross.val = \"loo\",\n",
    "                 precipitation = precip,\n",
    "                 wet.threshold = 1,\n",
    "                 window = c(90, 31),\n",
    "                 join.members = TRUE)\n",
    "}) \n",
    "names(data.bc.cross) <- varnames\n",
    "# Bias correction without cross-validation\n",
    "data.bc <- lapply(1:length(data), function(v)  {\n",
    "  pre <- FALSE\n",
    "  print(names(data)[v])\n",
    "  if (names(data)[v] == \"pr\") pre <- TRUE\n",
    "  biasCorrection(y = obs.data[[v]], x = data[[v]], \n",
    "                 method = \"eqm\",\n",
    "                 precipitation = pre,\n",
    "                 wet.threshold = 1,\n",
    "                 window = c(90, 31),\n",
    "                 join.members = TRUE)\n",
    "}) \n",
    "names(data.bc) <- varnames\n",
    "\n",
    "\n",
    "# save Rdata (*.rda file)\n",
    "save(data, file = paste0(dir.Rdata, \"interim075_WATExR_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_raw.rda\"))\n",
    "save(data.bc.cross, file = paste0(dir.Rdata, \"interim075_WATExR_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BCcross.rda\"))\n",
    "save(data.bc, file = paste0(dir.Rdata, \"interim075_WATExR_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BC.rda\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########## BUILD FINAL DATA --------------------------------------------------------------\n",
    "\n",
    "datatoexport <- data.bc\n",
    "\n",
    "# extract the data arrays of all variables from the list\n",
    "data <- lapply(datatoexport, function(x) x[[\"Data\"]])\n",
    "\n",
    "# Remove unwanted variables from output\n",
    "data[\"rsds\"] <- NULL \n",
    "data[\"rlds\"] <- NULL\n",
    "# Build data frame\n",
    "yymmdd <- as.Date(dates$start)\n",
    "hhmmss <- format(as.POSIXlt(dates$start), format = \"%H:%M:%S\") \n",
    "df <- data.frame(c(list(\"dates1\" = yymmdd, \"dates2\" = hhmmss)), data)\n",
    "\n",
    "\n",
    "########### EXPORT DATA ACCORDING TO THE WATExR ARCHIVE DESIGN -----------------------------\n",
    "## SEE the proposal for the WATExR Archive Design in:                                            \n",
    "## https://docs.google.com/document/d/1yzNtw9W_z_ziPQ6GrnSgD9ov5O1swnohndDTAWOgpwc/edit\n",
    "\n",
    "# Define metadata to generate the file name\n",
    "institution <- \"UC\"\n",
    "lake_id <- lakename\n",
    "ClimateModelName <- \"ERA-Interim\"\n",
    "ExperimentName <- \"reanalysis\"\n",
    "member <- \"member01\"\n",
    "freq <- \"day\"\n",
    "\n",
    "# Create directory and save file\n",
    "startTime <- format(as.POSIXlt(yymmdd[1]), format = \"%Y%m%d\")\n",
    "endTime <- format(tail(as.POSIXlt(yymmdd), n = 1), format = \"%Y%m%d\")\n",
    "dirName <- paste0(dir.data, lake_id, \"/CLIMATE/\", lake_id, \"_\", institution, \"_\", ClimateModelName, \"_\", ExperimentName, \"_\", member, \"_\", freq, \"_\", startTime, \"-\", endTime, \"/\", sep = \"\", collapse = NULL)\n",
    "dir.create(dirName, showWarnings = TRUE, recursive = TRUE, mode = \"0777\")\n",
    "write.table(df, paste0(dirName,\"meteo_file.dat\", sep = \"\", collapse = NULL), sep = \"\\t\", row.names = FALSE, col.names = FALSE, quote = FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
