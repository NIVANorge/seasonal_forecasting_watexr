{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: rJava\n",
      "Loading required package: loadeR.java\n",
      "Java version 11x amd64 by Ubuntu detected\n",
      "NetCDF Java Library v4.6.0-SNAPSHOT (23 Apr 2015) loaded and ready\n",
      "loadeR version 1.4.15 (2019-07-30) is loaded\n",
      "WARNING: Your current version of loadeR (v1.4.15) is not up-to-date\n",
      "Get the latest stable version (1.6.0) using <devtools::install_github('SantanderMetGroup/loadeR')>\n",
      "Please use 'citation(\"loadeR\")' to cite this package.\n",
      "transformeR version 1.6.1 (2019-11-01) is loaded\n",
      "Please see 'citation(\"transformeR\")' to cite this package.\n",
      "loadeR.ECOMS version 1.4.6 (2018-10-20) is loaded\n",
      "Please use 'citation(\"loadeR.ECOMS\")' to cite this package.\n",
      "Warning message:\n",
      "“no DISPLAY variable so Tk is not available”visualizeR version 1.5.0 (2019-10-04) is loaded\n",
      "WARNING: Your current version of visualizeR (v1.5.0) is not up-to-date\n",
      "Get the latest stable version (1.5.1) using <devtools::install_github('SantanderMetGroup/visualizeR')>\n",
      "Please see 'citation(\"visualizeR\")' to cite this package.\n",
      "\n",
      "Attaching package: ‘visualizeR’\n",
      "\n",
      "The following object is masked from ‘package:transformeR’:\n",
      "\n",
      "    clim2sgdf\n",
      "\n",
      "Loading required package: udunits2\n",
      "udunits system database read\n",
      "convertR version 0.1.2 (2018-06-28) is loaded\n",
      "  More information about the 'climate4R' ecosystem in: http://meteo.unican.es/climate4R\n",
      "\n",
      "Attaching package: ‘convertR’\n",
      "\n",
      "The following objects are masked from ‘package:loadeR’:\n",
      "\n",
      "    hurs2huss, huss2hurs\n",
      "\n",
      "drought4R version 0.3.0 (2019-06-17) is loaded\n",
      "WARNING: Your current version of drought4R (v0.3.0) is ahead of the master branch version (0.2.0)\n",
      "Development version may have an unexpected behaviour\n",
      "downscaleR version 3.1.0 (2019-07-09) is loaded\n",
      "Please use 'citation(\"downscaleR\")' to cite this package.\n"
     ]
    }
   ],
   "source": [
    "# Load packages. \n",
    "library(loadeR)\n",
    "library(transformeR)\n",
    "library(loadeR.ECOMS)\n",
    "library(visualizeR)\n",
    "library(convertR)\n",
    "library(drought4R)\n",
    "library(downscaleR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WATExR climate data processing\n",
    "\n",
    "This notebook aggregates the following R scripts (from [here](https://github.com/icra/WATExR/tree/master/R)):\n",
    "\n",
    " * `observations.R`\n",
    " * `reanalysis.R`\n",
    " * `seasonalForecast.R`\n",
    "\n",
    "Modifications have been made to suit the Morsa case study in Norway.\n",
    "\n",
    "The notebook rather messy and generates a lot of cell output, but it's useful to be able to run the whole workflow in one go. Note that downloading the data takes a long time (several hours), so it's probably best to run this e.g overnight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-01-15 12:39:00] Setting credentials...\n",
      "[2020-01-15 12:39:00] Success!\n",
      "Go to <http://www.meteo.unican.es/udg-tap/home> for details on your authorized groups and datasets\n"
     ]
    }
   ],
   "source": [
    "# Output path where the data will be saved (change to your local path).\n",
    "dir.data <- '/home/jovyan/projects/watexr/data/' \n",
    "dir.Rdata <- '/home/jovyan/projects/watexr/Rdata/'\n",
    "  \n",
    "# Define the geographical domain for the Morsa catchment\n",
    "latLim <- c(59.31, 59.90) \n",
    "lonLim <- c(10.63, 11.25) \n",
    "\n",
    "# Define the coordinates and name of the lake\n",
    "lake <- list(x = 10.895, y = 59.542) # Roughly the middle of Morsa catchment\n",
    "lakename <- \"Morsa\"\n",
    "\n",
    "# Define the period and the season\n",
    "years <- 1981:2010\n",
    "season <- 1:12 # Full year\n",
    "\n",
    "# Login in the TAP-UDG the climate4R libraries \n",
    "# More details about UDG in https://doi.org/10.1016/j.cliser.2017.07.001\n",
    "loginUDG(\"WATExR\", \"1234567890\")\n",
    "\n",
    "# Define metadata to generate the file name\n",
    "institution <- \"NIVA\"\n",
    "lake_id <- lakename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download EWEMBI\n",
    "\n",
    "Download historic, gridded, observational data (EWEMBI) for the Morsa catchment. The code is modified from the original [here](https://github.com/icra/WATExR/blob/master/R/observations.R)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Select dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset \n",
    "dataset <- \"PIK_Obs-EWEMBI\"\n",
    "\n",
    "# Check available variables in the dataset (EWEMBI)  \n",
    "di <- dataInventory(dataset)\n",
    "names(di)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data loading and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables to be loaded. Remove those not needed. \n",
    "variables <- c(\"uas\", \"vas\", \"ps\", \"tas\", \"pr\", \"rsds\", \"rlds\", \"hurs\")\n",
    "\n",
    "# Load observations (EWEMBI) with function loadGridData from package loadeR.\n",
    "# Data is loaded in a loop (function lapply) to load all variables in a single code line.\n",
    "# A list of grids is obtained, each slot in the list corresponds to a variable\n",
    "data.prelim <- lapply(variables, function(x) loadGridData(dataset, var = x, years = years, \n",
    "                                                   lonLim = lonLim, latLim = latLim, \n",
    "                                                   season = season))\n",
    "names(data.prelim) <- variables\n",
    "\n",
    "# Bilinear interpolation of the data to the location of the lake. See ?interpGrid for other methods.\n",
    "data.interp <- lapply(data.prelim, function(x) interpGrid(x, new.coordinates = lake, \n",
    "                                                   method = \"bilinear\", \n",
    "                                                   bilin.method = \"akima\"))\n",
    "\n",
    "#Convert pressure units to millibars with function udConvertGrid from package convertR.\n",
    "data.interp$ps <- udConvertGrid(data.interp$ps, new.units = \"millibars\")\n",
    "\n",
    "# Collect some common metadata (e.g. from variable uas)\n",
    "dates <- data.interp[[1]]$Dates\n",
    "xycoords <- getCoordinates(data.interp[[1]])\n",
    "\n",
    "## Compute cloud cover with function rad2cc from package convertR\n",
    "#clt <- rad2cc(rsds = data.interp$rsds, rlds = data.interp$rlds)\n",
    "#clt$Variable$varName <- \"cc\"\n",
    "#\n",
    "## Put all variables together\n",
    "#data <- c(data.interp, \"cc\" = list(clt))\n",
    "data <- data.interp\n",
    "\n",
    "############################################################################################\n",
    "############### RUN THE FOLLOWING CODE CHUNK IF YOU NEED POTENTIAL EVAPOTRANSPIRATION ######\n",
    "# Load needed variables \n",
    "tasmin <- loadGridData(dataset, var = \"tasmin\", years = years, \n",
    "                       lonLim = lonLim, latLim = latLim, \n",
    "                       season = season,  time = \"DD\", aggr.d = \"min\")\n",
    "tasmax <- loadGridData(dataset, var = \"tasmax\", years = years, \n",
    "                       lonLim = lonLim, latLim = latLim, \n",
    "                       season = season,  time = \"DD\", aggr.d = \"max\")\n",
    "\n",
    "# Compute potential evapotranspiration with function petGrid from package drought4R\n",
    "# For daily data the implemented method is hargreaves-samani (See ?petGrid for details):\n",
    "petH <- petGrid(tasmin = tasmin, \n",
    "                tasmax = tasmax,\n",
    "                method = \"hargreaves-samani\")\n",
    "\n",
    "# bilinear interpolation \n",
    "petH.interp <- interpGrid(petH, new.coordinates = lake, method = \"bilinear\", bilin.method = \"akima\")\n",
    "petH.interp$Variable$varName <- \"petH\"\n",
    "\n",
    "# Put all variables together\n",
    "data <- c(data, \"petH\" = list(petH.interp))\n",
    "###################### END OF THE CHUNK ####################################################\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Save results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Rdata for posterior bias correction of seasonal forecasts\n",
    "save(data, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \".rda\"))\n",
    "\n",
    "# extract the data arrays of all variables from the list\n",
    "data <- lapply(data, function(x) x[[\"Data\"]])\n",
    "# Remove unwanted variables from output\n",
    "data[\"rsds\"] <- NULL \n",
    "data[\"rlds\"] <- NULL\n",
    "# Build data frame\n",
    "yymmdd <- as.Date(dates$start)\n",
    "hhmmss <- format(as.POSIXlt(dates$start), format = \"%H:%M:%S\") \n",
    "df <- data.frame(c(list(\"dates1\" = yymmdd, \"dates2\" = hhmmss)), data)\n",
    "\n",
    "########### EXPORT DATA ACCORDING TO THE WATExR ARCHIVE DESIGN -----------------------------\n",
    "## SEE the proposal for the WATExR Archive Design in:                                            \n",
    "## https://docs.google.com/document/d/1yzNtw9W_z_ziPQ6GrnSgD9ov5O1swnohndDTAWOgpwc/edit\n",
    "\n",
    "# Define metadata to generate the file name\n",
    "ClimateModelName <- \"EWEMBI\"\n",
    "ExperimentName <- \"observations\"\n",
    "member <- \"member01\"\n",
    "freq <- \"day\"\n",
    "\n",
    "# Create directory and save file\n",
    "startTime <- format(as.POSIXlt(yymmdd[1]), format = \"%Y%m%d\")\n",
    "endTime <- format(tail(as.POSIXlt(yymmdd), n = 1), format = \"%Y%m%d\")\n",
    "dirName <- paste0(dir.data, lake_id, \"/CLIMATE/\", lake_id, \"_\", institution, \"_\", ClimateModelName, \"_\", ExperimentName, \"_\", member, \"_\", freq, \"_\", startTime, \"-\", endTime, \"/\", sep = \"\", collapse = NULL)\n",
    "dir.create(dirName, showWarnings = TRUE, recursive = TRUE, mode = \"0777\")\n",
    "write.table(df, paste0(dirName,\"meteo_file.dat\", sep = \"\", collapse = NULL), sep = \"\\t\", row.names = FALSE, col.names = FALSE, quote = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download and bias correct ERA-Interim\n",
    "\n",
    "Download historic, gridded, reanalysis data (ERA-Interim) for the Morsa catchment. The code is modified from the original [here](https://github.com/icra/WATExR/blob/master/R/reanalysis.R)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Select dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset <- \"ECMWF_ERA-Interim-ESD\"\n",
    "dataset <- \"http://meteo.unican.es/tds5/dodsC/interim/interim075_WATExR.ncml\"\n",
    "\n",
    "# Check available variables in the dataset (ERA-Interim)  \n",
    "di <- dataInventory(dataset)\n",
    "names(di)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Data loading and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the observational data (change to your local path).\n",
    "dir.Rdata.obs <- \"/home/jovyan/projects/watexr/Rdata/PIK_Obs-EWEMBI_1_2_3_4_5_6_7_8_9_10_11_12_uas_vas_ps_tas_pr_rsds_rlds_hurs_petH.rda\"\n",
    "obs.data <- get(load(dir.Rdata.obs))\n",
    "\n",
    "# Define the variables to be loaded (the same as in the observational data, \n",
    "# except clould cover (cc) and evapotranspiration (petH))\n",
    "varnames.obs <- sapply(obs.data, function(x) getVarNames(x)) # to check the variables in the observational data.\n",
    "varnames.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables to be loaded. Remove those not needed.\n",
    "variables <- c(\"uas\", \"vas\", \"ps\", \"tas\", \"pr\", \"rsds\", \"rlds\")\n",
    "                       \n",
    "# Define daily aggregation function for each variable selected. \n",
    "aggr.fun <- c(\"mean\", \"mean\", \"mean\", \"mean\", \"sum\", \"mean\", \"mean\")\n",
    "\n",
    "# Load reanalysis (ERA-Interim) with function loadGridData from package loadeR.\n",
    "# Data is loaded in a loop (function lapply) to load all variables in a single code line.\n",
    "# A list of grids is obtained, each slot in the list corresponds to a variable\n",
    "data.prelim <- lapply(1:length(variables), function(x) loadGridData(dataset, var = variables[x], years = years, \n",
    "                                                                    lonLim = lonLim, latLim = latLim, season = season, \n",
    "                                                                    time = \"DD\", aggr.d = aggr.fun[x]))\n",
    "\n",
    "# Deal with the special case of accumulated variables (get temporal intersection)\n",
    "data.prelim <- intersectGrid(data.prelim, type = \"temporal\", which.return = 1:length(variables))\n",
    "names(data.prelim) <- c(\"uas\", \"vas\", \"ps\", \"tas\", \"pr\", \"rsds\", \"rlds\")\n",
    "\n",
    "# Compute relative humidity from the mean temperature and the dew point with function tdps2hurs from package convertR\n",
    "tdps <- loadGridData(dataset, var = \"tdps\", years = years, \n",
    "                     lonLim = lonLim, latLim = latLim, \n",
    "                     season = season,  time = \"DD\", aggr.d = \"mean\")\n",
    "tdps <- intersectGrid(tdps, data.prelim$tas, which.return = 1)\n",
    "\n",
    "hurs <- data.prelim$tas # Predefine the object\n",
    "hurs$Data <- tdps2hurs(data.prelim$tas$Data, tdps$Data) # Assign the data matrix\n",
    "# Define correctly the metadata of the object:\n",
    "hurs$Variable$varName <- \"hurs\"\n",
    "attr(hurs$Variable,\"units\") <- \"%\"\n",
    "attr(hurs$Variable,\"description\") <- \"2 metre relative humidity\"\n",
    "attr(hurs$Variable,\"longname\") <- \"hurs\"\n",
    "# Include variables in data.prelim\n",
    "data.prelim <- c(data.prelim, \"hurs\" = list(hurs))\n",
    "\n",
    "# Compute wss\n",
    "wss <- data.prelim$uas\n",
    "wss$Data <- data.prelim$uas$Data^2 + data.prelim$vas$Data^2\n",
    "# Define correctly the metadata of the object:\n",
    "wss$Variable$varName <- \"wss\"\n",
    "attr(wss$Variable,\"units\") <- \"m s**-1\"\n",
    "attr(wss$Variable,\"description\") <- \"Near-Surface Wind Speed\"\n",
    "attr(wss$Variable,\"longname\") <- \"wss\"\n",
    "# Include variables in data.prelim\n",
    "data.prelim <- c(data.prelim, \"wss\" = list(wss))\n",
    "\n",
    "# Bilinear interpolation of the data to the location of the lake. See ?interpGrid for other methods.\n",
    "data.interp <- lapply(data.prelim, function(x) interpGrid(x, new.coordinates = lake, \n",
    "                                                          method = \"bilinear\", \n",
    "                                                          bilin.method = \"akima\"))\n",
    "\n",
    "# Convert pressure and temperature units to millibars and celsius with function udConvertGrid from package convertR.\n",
    "data.interp$ps <- udConvertGrid(data.interp$ps, new.units = \"millibars\") #No need SWAT\n",
    "data.interp$tas <- udConvertGrid(data.interp$tas, new.units = \"celsius\")\n",
    "\n",
    "# Convert radiation units from J/m2/12hours to W/m2\n",
    "data.interp$rsds$Data <- data.interp$rsds$Data/43200 \n",
    "attr(data.interp$rsds$Variable,\"units\") <- \"W.m-2\"\n",
    "data.interp$rlds$Data <- data.interp$rlds$Data/43200 \n",
    "attr(data.interp$rlds$Variable,\"units\") <- \"W.m-2\"\n",
    "\n",
    "#Convert relative humidity units to fractions with function udConvertGrid from package convertR.\n",
    "data.interp$hurs <- udConvertGrid(data.interp$hurs, new.units = \"\")\n",
    "\n",
    "#Convert shortwave radiation units to MJ/(m2*day) with function udConvertGrid from package convertR.\n",
    "data.interp$rsds <- udConvertGrid(data.interp$rsds, new.units = \"MJ m-2 day-1\")\n",
    "data.interp$rlds <- udConvertGrid(data.interp$rlds, new.units = \"MJ m-2 day-1\")\n",
    "\n",
    "## Compute cloud cover with function rad2cc\n",
    "#clt <- redim(rad2cc(rsds = data.interp$rsds, rlds = data.interp$rlds), drop = TRUE)\n",
    "#clt$Variable$varName <- \"cc\"\n",
    "#\n",
    "## Put all variables together\n",
    "#data <- c(data.interp, \"cc\" = list(clt))\n",
    "data <- data.interp\n",
    "\n",
    "############################################################################################\n",
    "############### RUN THE FOLLOWING CODE CHUNK IF YOU NEED POTENTIAL EVAPOTRANSPIRATION ######\n",
    "# Load needed variables \n",
    "tasmin <- loadGridData(dataset, var = \"tas\", years = years, \n",
    "                       lonLim = lonLim, latLim = latLim, \n",
    "                       season = season,  time = \"DD\", aggr.d = \"min\")\n",
    "tasmax <- loadGridData(dataset, var = \"tas\", years = years, \n",
    "                       lonLim = lonLim, latLim = latLim, \n",
    "                       season = season,  time = \"DD\", aggr.d = \"max\")\n",
    "# Compute potential evapotranspiration with function petGrid from package drought4R\n",
    "# For daily data the implemented method is hargreaves-samani (See ?petGrid for details)\n",
    "# petGrid function requires temperature in celsius. Convert temperature units to celsius.\n",
    "tasmax <- udConvertGrid(tasmax, new.units = \"celsius\")\n",
    "tasmin <- udConvertGrid(tasmin, new.units = \"celsius\")\n",
    "petH <- petGrid(tasmin = tasmin, \n",
    "                tasmax = tasmax,\n",
    "                method = \"hargreaves-samani\")\n",
    "\n",
    "# bilinear interpolation \n",
    "petH.interp <- interpGrid(petH, new.coordinates = lake, method = \"bilinear\", bilin.method = \"akima\")\n",
    "petH.interp$Variable$varName <- \"petH\"\n",
    "\n",
    "# Put all variables together\n",
    "data <- c(data, \"petH\" = list(petH.interp))\n",
    "###################### END OF THE CHUNK ####################################################\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variable consistency\n",
    "if (!all(names(obs.data) %in% names(data))) stop(\"variables in obs.data and data (seasonal forecast) do not match.\")\n",
    "\n",
    "#order variables\n",
    "data <- data[match(names(obs.data), names(data))]\n",
    "varnames <- names(data)\n",
    "\n",
    "# Subset observational data to the same dates as forecast data\n",
    "obs.data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 1)})\n",
    "data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 2)})\n",
    "names(obs.data) <- varnames\n",
    "names(data) <- varnames\n",
    "\n",
    "# Collect some common metadata (e.g. from variable uas)\n",
    "dates <- data[[1]]$Dates\n",
    "xycoords <- getCoordinates(data[[1]])\n",
    "\n",
    "# Bias correction with leave-one-year-out (\"loo\") cross-validation\n",
    "# type ?biasCorrection in R for more info about the parameter settings for bias correction.\n",
    "data.bc.cross <- lapply(1:length(data), function(x)  {\n",
    "  precip <- FALSE\n",
    "  if (names(data)[x] == \"pr\") precip <- TRUE\n",
    "  biasCorrection(y = obs.data[[x]], x = data[[x]], \n",
    "                 method = \"eqm\", cross.val = \"loo\",\n",
    "                 precipitation = precip,\n",
    "                 wet.threshold = 1,\n",
    "                 window = c(90, 31),\n",
    "                 join.members = TRUE)\n",
    "}) \n",
    "names(data.bc.cross) <- varnames\n",
    "\n",
    "# Bias correction without cross-validation\n",
    "data.bc <- lapply(1:length(data), function(v)  {\n",
    "  pre <- FALSE\n",
    "  print(names(data)[v])\n",
    "  if (names(data)[v] == \"pr\") pre <- TRUE\n",
    "  biasCorrection(y = obs.data[[v]], x = data[[v]], \n",
    "                 method = \"eqm\",\n",
    "                 precipitation = pre,\n",
    "                 wet.threshold = 1,\n",
    "                 window = c(90, 31),\n",
    "                 join.members = TRUE)\n",
    "}) \n",
    "names(data.bc) <- varnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Rdata (*.rda file)\n",
    "save(data, file = paste0(dir.Rdata, \"interim075_WATExR_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_raw.rda\"))\n",
    "save(data.bc.cross, file = paste0(dir.Rdata, \"interim075_WATExR_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BCcross.rda\"))\n",
    "save(data.bc, file = paste0(dir.Rdata, \"interim075_WATExR_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BC.rda\"))\n",
    "\n",
    "datatoexport <- data.bc\n",
    "\n",
    "# extract the data arrays of all variables from the list\n",
    "data <- lapply(datatoexport, function(x) x[[\"Data\"]])\n",
    "\n",
    "# Remove unwanted variables from output\n",
    "data[\"rsds\"] <- NULL \n",
    "data[\"rlds\"] <- NULL\n",
    "# Build data frame\n",
    "yymmdd <- as.Date(dates$start)\n",
    "hhmmss <- format(as.POSIXlt(dates$start), format = \"%H:%M:%S\") \n",
    "df <- data.frame(c(list(\"dates1\" = yymmdd, \"dates2\" = hhmmss)), data)\n",
    "\n",
    "########### EXPORT DATA ACCORDING TO THE WATExR ARCHIVE DESIGN -----------------------------\n",
    "## SEE the proposal for the WATExR Archive Design in:                                            \n",
    "## https://docs.google.com/document/d/1yzNtw9W_z_ziPQ6GrnSgD9ov5O1swnohndDTAWOgpwc/edit\n",
    "\n",
    "# Define metadata to generate the file name\n",
    "ClimateModelName <- \"ERA-Interim\"\n",
    "ExperimentName <- \"reanalysis\"\n",
    "member <- \"member01\"\n",
    "freq <- \"day\"\n",
    "\n",
    "# Create directory and save file\n",
    "startTime <- format(as.POSIXlt(yymmdd[1]), format = \"%Y%m%d\")\n",
    "endTime <- format(tail(as.POSIXlt(yymmdd), n = 1), format = \"%Y%m%d\")\n",
    "dirName <- paste0(dir.data, lake_id, \"/CLIMATE/\", lake_id, \"_\", institution, \"_\", ClimateModelName, \"_\", ExperimentName, \"_\", member, \"_\", freq, \"_\", startTime, \"-\", endTime, \"/\", sep = \"\", collapse = NULL)\n",
    "dir.create(dirName, showWarnings = TRUE, recursive = TRUE, mode = \"0777\")\n",
    "write.table(df, paste0(dirName,\"meteo_file.dat\", sep = \"\", collapse = NULL), sep = \"\\t\", row.names = FALSE, col.names = FALSE, quote = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download and bias correct seasonal forecast (S4) data\n",
    "\n",
    "Download gridded, seasonal forecast data (S4 15-member ensemble) for the Morsa catchment. The code is modified from the original [here](https://github.com/icra/WATExR/blob/master/R/seasonalForecast.R).\n",
    "\n",
    "**Note:** The code in this section is currently repeated **four times**, which is messy. This should be tidied/refactored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Winter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1. Select dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-01-15 12:39:11] Doing inventory ...\n",
      "[2020-01-15 12:39:35] Retrieving info for 'z1000mb' (45 vars remaining)\n",
      "[2020-01-15 12:39:36] Retrieving info for 'z700mb' (44 vars remaining)\n",
      "[2020-01-15 12:39:36] Retrieving info for 'z850mb' (43 vars remaining)\n",
      "[2020-01-15 12:39:38] Retrieving info for 'z500mb' (42 vars remaining)\n",
      "[2020-01-15 12:39:38] Retrieving info for 'z300mb' (41 vars remaining)\n",
      "[2020-01-15 12:39:39] Retrieving info for 'z200mb' (40 vars remaining)\n",
      "[2020-01-15 12:39:39] Retrieving info for 't1000mb' (39 vars remaining)\n",
      "[2020-01-15 12:39:40] Retrieving info for 't700mb' (38 vars remaining)\n",
      "[2020-01-15 12:39:41] Retrieving info for 't850mb' (37 vars remaining)\n",
      "[2020-01-15 12:39:41] Retrieving info for 't500mb' (36 vars remaining)\n",
      "[2020-01-15 12:39:42] Retrieving info for 't300mb' (35 vars remaining)\n",
      "[2020-01-15 12:39:42] Retrieving info for 't200mb' (34 vars remaining)\n",
      "[2020-01-15 12:39:43] Retrieving info for 'u1000mb' (33 vars remaining)\n",
      "[2020-01-15 12:39:44] Retrieving info for 'u700mb' (32 vars remaining)\n",
      "[2020-01-15 12:39:44] Retrieving info for 'u850mb' (31 vars remaining)\n",
      "[2020-01-15 12:39:45] Retrieving info for 'u500mb' (30 vars remaining)\n",
      "[2020-01-15 12:39:45] Retrieving info for 'u300mb' (29 vars remaining)\n",
      "[2020-01-15 12:39:46] Retrieving info for 'u200mb' (28 vars remaining)\n",
      "[2020-01-15 12:39:46] Retrieving info for 'v1000mb' (27 vars remaining)\n",
      "[2020-01-15 12:39:47] Retrieving info for 'v700mb' (26 vars remaining)\n",
      "[2020-01-15 12:39:48] Retrieving info for 'v850mb' (25 vars remaining)\n",
      "[2020-01-15 12:39:48] Retrieving info for 'v500mb' (24 vars remaining)\n",
      "[2020-01-15 12:39:49] Retrieving info for 'v300mb' (23 vars remaining)\n",
      "[2020-01-15 12:39:49] Retrieving info for 'v200mb' (22 vars remaining)\n",
      "[2020-01-15 12:39:50] Retrieving info for 'q1000mb' (21 vars remaining)\n",
      "[2020-01-15 12:39:51] Retrieving info for 'q700mb' (20 vars remaining)\n",
      "[2020-01-15 12:39:51] Retrieving info for 'q850mb' (19 vars remaining)\n",
      "[2020-01-15 12:39:52] Retrieving info for 'q500mb' (18 vars remaining)\n",
      "[2020-01-15 12:39:52] Retrieving info for 'q300mb' (17 vars remaining)\n",
      "[2020-01-15 12:39:53] Retrieving info for 'q200mb' (16 vars remaining)\n",
      "[2020-01-15 12:39:54] Retrieving info for 'zsfc' (15 vars remaining)\n",
      "[2020-01-15 12:39:54] Retrieving info for 'ssrd' (14 vars remaining)\n",
      "[2020-01-15 12:39:54] Retrieving info for 'strd' (13 vars remaining)\n",
      "[2020-01-15 12:39:54] Retrieving info for 'tcc' (12 vars remaining)\n",
      "[2020-01-15 12:39:55] Retrieving info for 'u10m' (11 vars remaining)\n",
      "[2020-01-15 12:39:55] Retrieving info for 'v10m' (10 vars remaining)\n",
      "[2020-01-15 12:39:55] Retrieving info for 'dpt2m' (9 vars remaining)\n",
      "[2020-01-15 12:39:55] Retrieving info for 't2m' (8 vars remaining)\n",
      "[2020-01-15 12:39:55] Retrieving info for 'mean2t24' (7 vars remaining)\n",
      "[2020-01-15 12:39:56] Retrieving info for 'sst' (6 vars remaining)\n",
      "[2020-01-15 12:39:56] Retrieving info for 'mx2t24' (5 vars remaining)\n",
      "[2020-01-15 12:39:56] Retrieving info for 'mn2t24' (4 vars remaining)\n",
      "[2020-01-15 12:39:56] Retrieving info for 'sd' (3 vars remaining)\n",
      "[2020-01-15 12:39:56] Retrieving info for 'sf' (2 vars remaining)\n",
      "[2020-01-15 12:39:56] Retrieving info for 'tp' (1 vars remaining)\n",
      "[2020-01-15 12:39:57] Retrieving info for 'mslp' (0 vars remaining)\n",
      "[2020-01-15 12:39:57] Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'z1000mb'</li>\n",
       "\t<li>'z700mb'</li>\n",
       "\t<li>'z850mb'</li>\n",
       "\t<li>'z500mb'</li>\n",
       "\t<li>'z300mb'</li>\n",
       "\t<li>'z200mb'</li>\n",
       "\t<li>'t1000mb'</li>\n",
       "\t<li>'t700mb'</li>\n",
       "\t<li>'t850mb'</li>\n",
       "\t<li>'t500mb'</li>\n",
       "\t<li>'t300mb'</li>\n",
       "\t<li>'t200mb'</li>\n",
       "\t<li>'u1000mb'</li>\n",
       "\t<li>'u700mb'</li>\n",
       "\t<li>'u850mb'</li>\n",
       "\t<li>'u500mb'</li>\n",
       "\t<li>'u300mb'</li>\n",
       "\t<li>'u200mb'</li>\n",
       "\t<li>'v1000mb'</li>\n",
       "\t<li>'v700mb'</li>\n",
       "\t<li>'v850mb'</li>\n",
       "\t<li>'v500mb'</li>\n",
       "\t<li>'v300mb'</li>\n",
       "\t<li>'v200mb'</li>\n",
       "\t<li>'q1000mb'</li>\n",
       "\t<li>'q700mb'</li>\n",
       "\t<li>'q850mb'</li>\n",
       "\t<li>'q500mb'</li>\n",
       "\t<li>'q300mb'</li>\n",
       "\t<li>'q200mb'</li>\n",
       "\t<li>'zsfc'</li>\n",
       "\t<li>'ssrd'</li>\n",
       "\t<li>'strd'</li>\n",
       "\t<li>'tcc'</li>\n",
       "\t<li>'u10m'</li>\n",
       "\t<li>'v10m'</li>\n",
       "\t<li>'dpt2m'</li>\n",
       "\t<li>'t2m'</li>\n",
       "\t<li>'mean2t24'</li>\n",
       "\t<li>'sst'</li>\n",
       "\t<li>'mx2t24'</li>\n",
       "\t<li>'mn2t24'</li>\n",
       "\t<li>'sd'</li>\n",
       "\t<li>'sf'</li>\n",
       "\t<li>'tp'</li>\n",
       "\t<li>'mslp'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'z1000mb'\n",
       "\\item 'z700mb'\n",
       "\\item 'z850mb'\n",
       "\\item 'z500mb'\n",
       "\\item 'z300mb'\n",
       "\\item 'z200mb'\n",
       "\\item 't1000mb'\n",
       "\\item 't700mb'\n",
       "\\item 't850mb'\n",
       "\\item 't500mb'\n",
       "\\item 't300mb'\n",
       "\\item 't200mb'\n",
       "\\item 'u1000mb'\n",
       "\\item 'u700mb'\n",
       "\\item 'u850mb'\n",
       "\\item 'u500mb'\n",
       "\\item 'u300mb'\n",
       "\\item 'u200mb'\n",
       "\\item 'v1000mb'\n",
       "\\item 'v700mb'\n",
       "\\item 'v850mb'\n",
       "\\item 'v500mb'\n",
       "\\item 'v300mb'\n",
       "\\item 'v200mb'\n",
       "\\item 'q1000mb'\n",
       "\\item 'q700mb'\n",
       "\\item 'q850mb'\n",
       "\\item 'q500mb'\n",
       "\\item 'q300mb'\n",
       "\\item 'q200mb'\n",
       "\\item 'zsfc'\n",
       "\\item 'ssrd'\n",
       "\\item 'strd'\n",
       "\\item 'tcc'\n",
       "\\item 'u10m'\n",
       "\\item 'v10m'\n",
       "\\item 'dpt2m'\n",
       "\\item 't2m'\n",
       "\\item 'mean2t24'\n",
       "\\item 'sst'\n",
       "\\item 'mx2t24'\n",
       "\\item 'mn2t24'\n",
       "\\item 'sd'\n",
       "\\item 'sf'\n",
       "\\item 'tp'\n",
       "\\item 'mslp'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'z1000mb'\n",
       "2. 'z700mb'\n",
       "3. 'z850mb'\n",
       "4. 'z500mb'\n",
       "5. 'z300mb'\n",
       "6. 'z200mb'\n",
       "7. 't1000mb'\n",
       "8. 't700mb'\n",
       "9. 't850mb'\n",
       "10. 't500mb'\n",
       "11. 't300mb'\n",
       "12. 't200mb'\n",
       "13. 'u1000mb'\n",
       "14. 'u700mb'\n",
       "15. 'u850mb'\n",
       "16. 'u500mb'\n",
       "17. 'u300mb'\n",
       "18. 'u200mb'\n",
       "19. 'v1000mb'\n",
       "20. 'v700mb'\n",
       "21. 'v850mb'\n",
       "22. 'v500mb'\n",
       "23. 'v300mb'\n",
       "24. 'v200mb'\n",
       "25. 'q1000mb'\n",
       "26. 'q700mb'\n",
       "27. 'q850mb'\n",
       "28. 'q500mb'\n",
       "29. 'q300mb'\n",
       "30. 'q200mb'\n",
       "31. 'zsfc'\n",
       "32. 'ssrd'\n",
       "33. 'strd'\n",
       "34. 'tcc'\n",
       "35. 'u10m'\n",
       "36. 'v10m'\n",
       "37. 'dpt2m'\n",
       "38. 't2m'\n",
       "39. 'mean2t24'\n",
       "40. 'sst'\n",
       "41. 'mx2t24'\n",
       "42. 'mn2t24'\n",
       "43. 'sd'\n",
       "44. 'sf'\n",
       "45. 'tp'\n",
       "46. 'mslp'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"z1000mb\"  \"z700mb\"   \"z850mb\"   \"z500mb\"   \"z300mb\"   \"z200mb\"  \n",
       " [7] \"t1000mb\"  \"t700mb\"   \"t850mb\"   \"t500mb\"   \"t300mb\"   \"t200mb\"  \n",
       "[13] \"u1000mb\"  \"u700mb\"   \"u850mb\"   \"u500mb\"   \"u300mb\"   \"u200mb\"  \n",
       "[19] \"v1000mb\"  \"v700mb\"   \"v850mb\"   \"v500mb\"   \"v300mb\"   \"v200mb\"  \n",
       "[25] \"q1000mb\"  \"q700mb\"   \"q850mb\"   \"q500mb\"   \"q300mb\"   \"q200mb\"  \n",
       "[31] \"zsfc\"     \"ssrd\"     \"strd\"     \"tcc\"      \"u10m\"     \"v10m\"    \n",
       "[37] \"dpt2m\"    \"t2m\"      \"mean2t24\" \"sst\"      \"mx2t24\"   \"mn2t24\"  \n",
       "[43] \"sd\"       \"sf\"       \"tp\"       \"mslp\"    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(java.parameters = \"-Xmx8000m\")\n",
    "\n",
    "# Define the members\n",
    "mem <- 1:15\n",
    "# Define the lead month\n",
    "lead.month <- 0\n",
    "# Define period and season\n",
    "season <- c(11,12,1) # Winter\n",
    "\n",
    "# Define the dataset \n",
    "dataset <- \"System4_seasonal_15\" # or \"CFSv2_seasonal\"\n",
    "\n",
    "# Check available variables in the dataset (System4)  \n",
    "di <- dataInventory(\"http://www.meteo.unican.es/tds5/dodsC/system4/System4_Seasonal_15Members.ncml\") # or \"http://meteo.unican.es/tds5/dodsC/cfsrr/CFSv2_Seasonal.ncml\"\n",
    "names(di)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2. Data loading and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the observational data (change to your local path).\n",
    "dir.Rdata.obs <- \"/home/jovyan/projects/watexr/Rdata/PIK_Obs-EWEMBI_1_2_3_4_5_6_7_8_9_10_11_12_uas_vas_ps_tas_pr_rsds_rlds_hurs_petH.rda\"\n",
    "obs.data <- get(load(dir.Rdata.obs))\n",
    "\n",
    "# Define the variables to be loaded (the same as in the observational data, \n",
    "# except clould cover (cc) and evapotranspiration (petH))\n",
    "sapply(obs.data, function(x) getVarNames(x)) # to check the variables in the observational data.\n",
    "variables <- c(\"uas\", \"vas\", \"ps\", \"tas\", \"pr\", \"rsds\", \"rlds\", \"hurs\")\n",
    "\n",
    "# Define daily aggregation function for each variable selected\n",
    "aggr.fun <- c(\"mean\", \"mean\", \"mean\", \"mean\", \"sum\", \"mean\", \"mean\", \"mean\")\n",
    "\n",
    "# Load seasonal forecast data (System4 or CFS) with function loadECOMS\n",
    "# Data is loaded in a loop (función lapply) to load all variables in a single code line.\n",
    "# A list of grids is obtained, each slot in the list corresponds to a variable\n",
    "data.prelim <- lapply(1:length(variables), function(x) loadECOMS(dataset, var = variables[x], years = years, \n",
    "                                                          members = mem, leadMonth = lead.month,\n",
    "                                                          lonLim = lonLim, latLim = latLim, season = season, \n",
    "                                                          time = \"DD\", aggr.d = aggr.fun[x]))\n",
    "names(data.prelim) <- variables\n",
    "\n",
    "# Bilinear interpolation of the data to the location of the lake\n",
    "data.interp <- lapply(data.prelim, function(x) interpGrid(x, new.coordinates = lake, \n",
    "                                                          method = \"bilinear\", \n",
    "                                                          bilin.method = \"akima\"))\n",
    "\n",
    "# Convert pressure units to millibars with function udConvertGrid from package convertR.\n",
    "data.interp$ps <- udConvertGrid(data.interp$ps, new.units = \"millibars\")\n",
    "\n",
    "## Compute cloud cover with function rad2cc\n",
    "#clt <- rad2cc(rsds = data.interp$rsds, rlds = data.interp$rlds)\n",
    "#clt$Variable$varName <- \"cc\"\n",
    "#\n",
    "## Put all variables together\n",
    "#data <- c(data.interp, \"cc\" = list(clt))\n",
    "data <- data.interp\n",
    "\n",
    "############################################################################################\n",
    "############### RUN THE FOLLOWING CODE CHUNK IF YOU NEED POTENTIAL EVAPOTRANSPIRATION ######\n",
    "# Load needed variables \n",
    "tasmin <- loadECOMS(dataset, var = \"tasmin\", years = years, \n",
    "                    lonLim = lonLim, latLim = latLim, \n",
    "                    leadMonth = lead.month, members = mem,\n",
    "                    season = season, time = \"DD\", aggr.d = \"min\")\n",
    "tasmax <- loadECOMS(dataset, var = \"tasmax\", years = years, \n",
    "                    lonLim = lonLim, latLim = latLim, \n",
    "                    leadMonth = lead.month, members = mem,\n",
    "                    season = season, time = \"DD\", aggr.d = \"max\")\n",
    "\n",
    "# Compute potential evapotranspiration with function petGrid from package drought4R\n",
    "# For daily data the implemented method is hargreaves-samani (See ?petGrid for details):\n",
    "petH <- petGrid(tasmin = tasmin, \n",
    "                tasmax = tasmax,\n",
    "                method = \"hargreaves-samani\")\n",
    "\n",
    "# bilinear interpolation \n",
    "petH.interp <- interpGrid(petH, new.coordinates = lake, method = \"bilinear\", bilin.method = \"akima\")\n",
    "petH.interp$Variable$varName <- \"petH\"\n",
    "\n",
    "# Put all variables together\n",
    "data <- c(data, \"petH\" = list(petH.interp))\n",
    "###################### END OF THE CHUNK ####################################################\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3. Bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset all datasets to the same Dates as the hindcast precipitation. Note that we compute daily accumulated \n",
    "# precipitation, for this reason this variable has no value for the first day of every season.  \n",
    "if (sum(names(data)==\"pr\")>0){\n",
    "  data <- lapply(1:length(data), function(x)  {intersectGrid(data[[x]], data[[which(names(data)==\"pr\")]], type = \"temporal\", which.return = 1)}) \n",
    "  names(data) <- sapply(data, function(x) getVarNames(x))\n",
    "  obs.data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 1)}) \n",
    "  names(obs.data) <- sapply(obs.data, function(x) getVarNames(x))\n",
    "} else{\n",
    "  obs.data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 1)}) \n",
    "  names(obs.data) <- sapply(obs.data, function(x) getVarNames(x))  \n",
    "}\n",
    "\n",
    "# Check variable consistency\n",
    "if (!identical(names(obs.data), names(data))) stop(\"variables in obs.data and data (seasonal forecast) do not match.\")\n",
    "\n",
    "# Bias correction with leave-one-year-out (\"loo\") cross-validation\n",
    "# type ?biasCorrection in R for more info about the parameter settings for bias correction.\n",
    "data.bc.cross <- lapply(1:length(data), function(x)  {\n",
    "    precip <- FALSE\n",
    "    if (names(data)[x] == \"pr\") precip <- TRUE\n",
    "    biasCorrection(y = obs.data[[x]], x = data[[x]], \n",
    "                method = \"eqm\", cross.val = \"loo\",\n",
    "                precipitation = precip,\n",
    "                wet.threshold = 1,\n",
    "                join.members = TRUE)\n",
    "  }) \n",
    "names(data.bc.cross) <- names(data)\n",
    "                            \n",
    "# Bias correction without cross-validation\n",
    "data.bc <- lapply(1:length(data), function(v)  {\n",
    "    pre <- FALSE\n",
    "    if (names(data)[v] == \"pr\") pre <- TRUE\n",
    "    biasCorrection(y = obs.data[[v]], x = data[[v]], \n",
    "                 method = \"eqm\",\n",
    "                 precipitation = pre,\n",
    "                 wet.threshold = 1,\n",
    "                 join.members = TRUE)\n",
    "}) \n",
    "names(data.bc) <- names(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.4. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Rdata (*.rda file)\n",
    "save(data, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_raw.rda\"))\n",
    "save(data.bc.cross, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BCcross.rda\"))\n",
    "save(data.bc, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BC.rda\"))\n",
    "\n",
    "########## BUILD FINAL DATA AND EXPORT ACCORDING TO THE WATExR ARCHIVE DESIGN -----------------------\n",
    "## SEE the proposal for the WATExR Archive Design in:                                            \n",
    "## https://docs.google.com/document/d/1yzNtw9W_z_ziPQ6GrnSgD9ov5O1swnohndDTAWOgpwc/edit\n",
    "\n",
    "# Select the object to export (can be 'data.bc', 'data.bc.cross' or 'data')\n",
    "datatoexport <- data.bc\n",
    "\n",
    "# Collect some common metadata (e.g. from variable uas)\n",
    "dates <- datatoexport[[1]]$Dates\n",
    "xycoords <- getCoordinates(datatoexport[[1]])\n",
    "\n",
    "# Give format to dates\n",
    "yymmdd <- as.Date(dates$start)\n",
    "hhmmss <- format(as.POSIXlt(dates$start), format = \"%H:%M:%S\") \n",
    "\n",
    "# Define metadata to generate the file name\n",
    "ClimateModelName <- dataset\n",
    "ExperimentName <- \"seasonal\"\n",
    "freq <- \"day\"\n",
    "\n",
    "# Save a single file for each member\n",
    "for (i in mem) {\n",
    "  # Build data.frame for a single member\n",
    "  single.member <- lapply(datatoexport, function(x) subsetGrid(x, members = i))\n",
    "  single.member <- lapply(single.member, function(x) x$Data)\n",
    "  # Remove unwanted variables\n",
    "  single.member[\"rsds\"] <- NULL\n",
    "  single.member[\"rlds\"] <- NULL\n",
    "  # data.frame creation\n",
    "  df <- data.frame(c(list(\"dates1\" = yymmdd, \"dates2\" = hhmmss)), single.member)\n",
    "  if (i < 10) {\n",
    "    member <- paste0(\"member0\", i, sep = \"\", collapse = NULL)\n",
    "  } else {\n",
    "    member <- paste0(\"member\", i, sep = \"\", collapse = NULL)\n",
    "  }    \n",
    "  startTime <- format(as.POSIXlt(yymmdd[1]), format = \"%Y%m%d\")\n",
    "  endTime <- format(tail(as.POSIXlt(yymmdd), n = 1), format = \"%Y%m%d\")\n",
    "  dirName <- paste0(dir.data, lake_id, \"/CLIMATE/\", lake_id, \"_\", institution, \"_\", ClimateModelName, \"_\", ExperimentName, \"_\", member, \"_\", freq,\"_\", startTime, \"-\", endTime, \"/\", sep = \"\", collapse = NULL)\n",
    "  dir.create(dirName, showWarnings = TRUE, recursive = TRUE, mode = \"0777\")\n",
    "  write.table(df, paste0(dirName, \"meteo_file.dat\", sep = \"\", collapse = NULL), sep = \"\\t\", row.names = FALSE, col.names = FALSE, quote = FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Spring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1. Select dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(java.parameters = \"-Xmx8000m\")\n",
    "\n",
    "# Define the members\n",
    "mem <- 1:15\n",
    "# Define the lead month\n",
    "lead.month <- 0\n",
    "# Define period and season\n",
    "season <- c(2,3,4)   # Spring\n",
    "\n",
    "# Define the dataset \n",
    "dataset <- \"System4_seasonal_15\" # or \"CFSv2_seasonal\"\n",
    "\n",
    "# Check available variables in the dataset (System4)  \n",
    "di <- dataInventory(\"http://www.meteo.unican.es/tds5/dodsC/system4/System4_Seasonal_15Members.ncml\") # or \"http://meteo.unican.es/tds5/dodsC/cfsrr/CFSv2_Seasonal.ncml\"\n",
    "names(di)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. Data loading and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the observational data (change to your local path).\n",
    "dir.Rdata.obs <- \"/home/jovyan/projects/watexr/Rdata/PIK_Obs-EWEMBI_1_2_3_4_5_6_7_8_9_10_11_12_uas_vas_ps_tas_pr_rsds_rlds_hurs_petH.rda\"\n",
    "obs.data <- get(load(dir.Rdata.obs))\n",
    "\n",
    "# Define the variables to be loaded (the same as in the observational data, \n",
    "# except clould cover (cc) and evapotranspiration (petH))\n",
    "sapply(obs.data, function(x) getVarNames(x)) # to check the variables in the observational data.\n",
    "variables <- c(\"uas\", \"vas\", \"ps\", \"tas\", \"pr\", \"rsds\", \"rlds\", \"hurs\")\n",
    "\n",
    "# Define daily aggregation function for each variable selected\n",
    "aggr.fun <- c(\"mean\", \"mean\", \"mean\", \"mean\", \"sum\", \"mean\", \"mean\", \"mean\")\n",
    "\n",
    "# Load seasonal forecast data (System4 or CFS) with function loadECOMS\n",
    "# Data is loaded in a loop (función lapply) to load all variables in a single code line.\n",
    "# A list of grids is obtained, each slot in the list corresponds to a variable\n",
    "data.prelim <- lapply(1:length(variables), function(x) loadECOMS(dataset, var = variables[x], years = years, \n",
    "                                                          members = mem, leadMonth = lead.month,\n",
    "                                                          lonLim = lonLim, latLim = latLim, season = season, \n",
    "                                                          time = \"DD\", aggr.d = aggr.fun[x]))\n",
    "names(data.prelim) <- variables\n",
    "\n",
    "# Bilinear interpolation of the data to the location of the lake\n",
    "data.interp <- lapply(data.prelim, function(x) interpGrid(x, new.coordinates = lake, \n",
    "                                                          method = \"bilinear\", \n",
    "                                                          bilin.method = \"akima\"))\n",
    "\n",
    "# Convert pressure units to millibars with function udConvertGrid from package convertR.\n",
    "data.interp$ps <- udConvertGrid(data.interp$ps, new.units = \"millibars\")\n",
    "\n",
    "## Compute cloud cover with function rad2cc\n",
    "#clt <- rad2cc(rsds = data.interp$rsds, rlds = data.interp$rlds)\n",
    "#clt$Variable$varName <- \"cc\"\n",
    "#\n",
    "## Put all variables together\n",
    "#data <- c(data.interp, \"cc\" = list(clt))\n",
    "data <- data.interp\n",
    "\n",
    "############################################################################################\n",
    "############### RUN THE FOLLOWING CODE CHUNK IF YOU NEED POTENTIAL EVAPOTRANSPIRATION ######\n",
    "# Load needed variables \n",
    "tasmin <- loadECOMS(dataset, var = \"tasmin\", years = years, \n",
    "                    lonLim = lonLim, latLim = latLim, \n",
    "                    leadMonth = lead.month, members = mem,\n",
    "                    season = season, time = \"DD\", aggr.d = \"min\")\n",
    "tasmax <- loadECOMS(dataset, var = \"tasmax\", years = years, \n",
    "                    lonLim = lonLim, latLim = latLim, \n",
    "                    leadMonth = lead.month, members = mem,\n",
    "                    season = season, time = \"DD\", aggr.d = \"max\")\n",
    "\n",
    "# Compute potential evapotranspiration with function petGrid from package drought4R\n",
    "# For daily data the implemented method is hargreaves-samani (See ?petGrid for details):\n",
    "petH <- petGrid(tasmin = tasmin, \n",
    "                tasmax = tasmax,\n",
    "                method = \"hargreaves-samani\")\n",
    "\n",
    "# bilinear interpolation \n",
    "petH.interp <- interpGrid(petH, new.coordinates = lake, method = \"bilinear\", bilin.method = \"akima\")\n",
    "petH.interp$Variable$varName <- \"petH\"\n",
    "\n",
    "# Put all variables together\n",
    "data <- c(data, \"petH\" = list(petH.interp))\n",
    "###################### END OF THE CHUNK ####################################################\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3. Bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset all datasets to the same Dates as the hindcast precipitation. Note that we compute daily accumulated \n",
    "# precipitation, for this reason this variable has no value for the first day of every season.  \n",
    "if (sum(names(data)==\"pr\")>0){\n",
    "  data <- lapply(1:length(data), function(x)  {intersectGrid(data[[x]], data[[which(names(data)==\"pr\")]], type = \"temporal\", which.return = 1)}) \n",
    "  names(data) <- sapply(data, function(x) getVarNames(x))\n",
    "  obs.data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 1)}) \n",
    "  names(obs.data) <- sapply(obs.data, function(x) getVarNames(x))\n",
    "} else{\n",
    "  obs.data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 1)}) \n",
    "  names(obs.data) <- sapply(obs.data, function(x) getVarNames(x))  \n",
    "}\n",
    "\n",
    "# Check variable consistency\n",
    "if (!identical(names(obs.data), names(data))) stop(\"variables in obs.data and data (seasonal forecast) do not match.\")\n",
    "\n",
    "# Bias correction with leave-one-year-out (\"loo\") cross-validation\n",
    "# type ?biasCorrection in R for more info about the parameter settings for bias correction.\n",
    "data.bc.cross <- lapply(1:length(data), function(x)  {\n",
    "    precip <- FALSE\n",
    "    if (names(data)[x] == \"pr\") precip <- TRUE\n",
    "    biasCorrection(y = obs.data[[x]], x = data[[x]], \n",
    "                method = \"eqm\", cross.val = \"loo\",\n",
    "                precipitation = precip,\n",
    "                wet.threshold = 1,\n",
    "                join.members = TRUE)\n",
    "  }) \n",
    "names(data.bc.cross) <- names(data)\n",
    "                            \n",
    "# Bias correction without cross-validation\n",
    "data.bc <- lapply(1:length(data), function(v)  {\n",
    "    pre <- FALSE\n",
    "    if (names(data)[v] == \"pr\") pre <- TRUE\n",
    "    biasCorrection(y = obs.data[[v]], x = data[[v]], \n",
    "                 method = \"eqm\",\n",
    "                 precipitation = pre,\n",
    "                 wet.threshold = 1,\n",
    "                 join.members = TRUE)\n",
    "}) \n",
    "names(data.bc) <- names(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Rdata (*.rda file)\n",
    "save(data, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_raw.rda\"))\n",
    "save(data.bc.cross, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BCcross.rda\"))\n",
    "save(data.bc, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BC.rda\"))\n",
    "\n",
    "########## BUILD FINAL DATA AND EXPORT ACCORDING TO THE WATExR ARCHIVE DESIGN -----------------------\n",
    "## SEE the proposal for the WATExR Archive Design in:                                            \n",
    "## https://docs.google.com/document/d/1yzNtw9W_z_ziPQ6GrnSgD9ov5O1swnohndDTAWOgpwc/edit\n",
    "\n",
    "# Select the object to export (can be 'data.bc', 'data.bc.cross' or 'data')\n",
    "datatoexport <- data.bc\n",
    "\n",
    "# Collect some common metadata (e.g. from variable uas)\n",
    "dates <- datatoexport[[1]]$Dates\n",
    "xycoords <- getCoordinates(datatoexport[[1]])\n",
    "\n",
    "# Give format to dates\n",
    "yymmdd <- as.Date(dates$start)\n",
    "hhmmss <- format(as.POSIXlt(dates$start), format = \"%H:%M:%S\") \n",
    "\n",
    "# Define metadata to generate the file name\n",
    "ClimateModelName <- dataset\n",
    "ExperimentName <- \"seasonal\"\n",
    "freq <- \"day\"\n",
    "\n",
    "# Save a single file for each member\n",
    "for (i in mem) {\n",
    "  # Build data.frame for a single member\n",
    "  single.member <- lapply(datatoexport, function(x) subsetGrid(x, members = i))\n",
    "  single.member <- lapply(single.member, function(x) x$Data)\n",
    "  # Remove unwanted variables\n",
    "  single.member[\"rsds\"] <- NULL\n",
    "  single.member[\"rlds\"] <- NULL\n",
    "  # data.frame creation\n",
    "  df <- data.frame(c(list(\"dates1\" = yymmdd, \"dates2\" = hhmmss)), single.member)\n",
    "  if (i < 10) {\n",
    "    member <- paste0(\"member0\", i, sep = \"\", collapse = NULL)\n",
    "  } else {\n",
    "    member <- paste0(\"member\", i, sep = \"\", collapse = NULL)\n",
    "  }    \n",
    "  startTime <- format(as.POSIXlt(yymmdd[1]), format = \"%Y%m%d\")\n",
    "  endTime <- format(tail(as.POSIXlt(yymmdd), n = 1), format = \"%Y%m%d\")\n",
    "  dirName <- paste0(dir.data, lake_id, \"/CLIMATE/\", lake_id, \"_\", institution, \"_\", ClimateModelName, \"_\", ExperimentName, \"_\", member, \"_\", freq,\"_\", startTime, \"-\", endTime, \"/\", sep = \"\", collapse = NULL)\n",
    "  dir.create(dirName, showWarnings = TRUE, recursive = TRUE, mode = \"0777\")\n",
    "  write.table(df, paste0(dirName, \"meteo_file.dat\", sep = \"\", collapse = NULL), sep = \"\\t\", row.names = FALSE, col.names = FALSE, quote = FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Early summer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1. Select dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(java.parameters = \"-Xmx8000m\")\n",
    "\n",
    "# Define the members\n",
    "mem <- 1:15\n",
    "# Define the lead month\n",
    "lead.month <- 0\n",
    "# Define period and season\n",
    "season <- c(5,6,7)   # Early summer\n",
    "\n",
    "# Define the dataset \n",
    "dataset <- \"System4_seasonal_15\" # or \"CFSv2_seasonal\"\n",
    "\n",
    "# Check available variables in the dataset (System4)  \n",
    "di <- dataInventory(\"http://www.meteo.unican.es/tds5/dodsC/system4/System4_Seasonal_15Members.ncml\") # or \"http://meteo.unican.es/tds5/dodsC/cfsrr/CFSv2_Seasonal.ncml\"\n",
    "names(di)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2. Data loading and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the observational data (change to your local path).\n",
    "dir.Rdata.obs <- \"/home/jovyan/projects/watexr/Rdata/PIK_Obs-EWEMBI_1_2_3_4_5_6_7_8_9_10_11_12_uas_vas_ps_tas_pr_rsds_rlds_hurs_petH.rda\"\n",
    "obs.data <- get(load(dir.Rdata.obs))\n",
    "\n",
    "# Define the variables to be loaded (the same as in the observational data, \n",
    "# except clould cover (cc) and evapotranspiration (petH))\n",
    "sapply(obs.data, function(x) getVarNames(x)) # to check the variables in the observational data.\n",
    "variables <- c(\"uas\", \"vas\", \"ps\", \"tas\", \"pr\", \"rsds\", \"rlds\", \"hurs\")\n",
    "\n",
    "# Define daily aggregation function for each variable selected\n",
    "aggr.fun <- c(\"mean\", \"mean\", \"mean\", \"mean\", \"sum\", \"mean\", \"mean\", \"mean\")\n",
    "\n",
    "# Load seasonal forecast data (System4 or CFS) with function loadECOMS\n",
    "# Data is loaded in a loop (función lapply) to load all variables in a single code line.\n",
    "# A list of grids is obtained, each slot in the list corresponds to a variable\n",
    "data.prelim <- lapply(1:length(variables), function(x) loadECOMS(dataset, var = variables[x], years = years, \n",
    "                                                          members = mem, leadMonth = lead.month,\n",
    "                                                          lonLim = lonLim, latLim = latLim, season = season, \n",
    "                                                          time = \"DD\", aggr.d = aggr.fun[x]))\n",
    "names(data.prelim) <- variables\n",
    "\n",
    "# Bilinear interpolation of the data to the location of the lake\n",
    "data.interp <- lapply(data.prelim, function(x) interpGrid(x, new.coordinates = lake, \n",
    "                                                          method = \"bilinear\", \n",
    "                                                          bilin.method = \"akima\"))\n",
    "\n",
    "# Convert pressure units to millibars with function udConvertGrid from package convertR.\n",
    "data.interp$ps <- udConvertGrid(data.interp$ps, new.units = \"millibars\")\n",
    "\n",
    "## Compute cloud cover with function rad2cc\n",
    "#clt <- rad2cc(rsds = data.interp$rsds, rlds = data.interp$rlds)\n",
    "#clt$Variable$varName <- \"cc\"\n",
    "#\n",
    "## Put all variables together\n",
    "#data <- c(data.interp, \"cc\" = list(clt))\n",
    "data <- data.interp\n",
    "\n",
    "############################################################################################\n",
    "############### RUN THE FOLLOWING CODE CHUNK IF YOU NEED POTENTIAL EVAPOTRANSPIRATION ######\n",
    "# Load needed variables \n",
    "tasmin <- loadECOMS(dataset, var = \"tasmin\", years = years, \n",
    "                    lonLim = lonLim, latLim = latLim, \n",
    "                    leadMonth = lead.month, members = mem,\n",
    "                    season = season, time = \"DD\", aggr.d = \"min\")\n",
    "tasmax <- loadECOMS(dataset, var = \"tasmax\", years = years, \n",
    "                    lonLim = lonLim, latLim = latLim, \n",
    "                    leadMonth = lead.month, members = mem,\n",
    "                    season = season, time = \"DD\", aggr.d = \"max\")\n",
    "\n",
    "# Compute potential evapotranspiration with function petGrid from package drought4R\n",
    "# For daily data the implemented method is hargreaves-samani (See ?petGrid for details):\n",
    "petH <- petGrid(tasmin = tasmin, \n",
    "                tasmax = tasmax,\n",
    "                method = \"hargreaves-samani\")\n",
    "\n",
    "# bilinear interpolation \n",
    "petH.interp <- interpGrid(petH, new.coordinates = lake, method = \"bilinear\", bilin.method = \"akima\")\n",
    "petH.interp$Variable$varName <- \"petH\"\n",
    "\n",
    "# Put all variables together\n",
    "data <- c(data, \"petH\" = list(petH.interp))\n",
    "###################### END OF THE CHUNK ####################################################\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3. Bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset all datasets to the same Dates as the hindcast precipitation. Note that we compute daily accumulated \n",
    "# precipitation, for this reason this variable has no value for the first day of every season.  \n",
    "if (sum(names(data)==\"pr\")>0){\n",
    "  data <- lapply(1:length(data), function(x)  {intersectGrid(data[[x]], data[[which(names(data)==\"pr\")]], type = \"temporal\", which.return = 1)}) \n",
    "  names(data) <- sapply(data, function(x) getVarNames(x))\n",
    "  obs.data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 1)}) \n",
    "  names(obs.data) <- sapply(obs.data, function(x) getVarNames(x))\n",
    "} else{\n",
    "  obs.data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 1)}) \n",
    "  names(obs.data) <- sapply(obs.data, function(x) getVarNames(x))  \n",
    "}\n",
    "\n",
    "# Check variable consistency\n",
    "if (!identical(names(obs.data), names(data))) stop(\"variables in obs.data and data (seasonal forecast) do not match.\")\n",
    "\n",
    "# Bias correction with leave-one-year-out (\"loo\") cross-validation\n",
    "# type ?biasCorrection in R for more info about the parameter settings for bias correction.\n",
    "data.bc.cross <- lapply(1:length(data), function(x)  {\n",
    "    precip <- FALSE\n",
    "    if (names(data)[x] == \"pr\") precip <- TRUE\n",
    "    biasCorrection(y = obs.data[[x]], x = data[[x]], \n",
    "                method = \"eqm\", cross.val = \"loo\",\n",
    "                precipitation = precip,\n",
    "                wet.threshold = 1,\n",
    "                join.members = TRUE)\n",
    "  }) \n",
    "names(data.bc.cross) <- names(data)\n",
    "                            \n",
    "# Bias correction without cross-validation\n",
    "data.bc <- lapply(1:length(data), function(v)  {\n",
    "    pre <- FALSE\n",
    "    if (names(data)[v] == \"pr\") pre <- TRUE\n",
    "    biasCorrection(y = obs.data[[v]], x = data[[v]], \n",
    "                 method = \"eqm\",\n",
    "                 precipitation = pre,\n",
    "                 wet.threshold = 1,\n",
    "                 join.members = TRUE)\n",
    "}) \n",
    "names(data.bc) <- names(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Rdata (*.rda file)\n",
    "save(data, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_raw.rda\"))\n",
    "save(data.bc.cross, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BCcross.rda\"))\n",
    "save(data.bc, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BC.rda\"))\n",
    "\n",
    "########## BUILD FINAL DATA AND EXPORT ACCORDING TO THE WATExR ARCHIVE DESIGN -----------------------\n",
    "## SEE the proposal for the WATExR Archive Design in:                                            \n",
    "## https://docs.google.com/document/d/1yzNtw9W_z_ziPQ6GrnSgD9ov5O1swnohndDTAWOgpwc/edit\n",
    "\n",
    "# Select the object to export (can be 'data.bc', 'data.bc.cross' or 'data')\n",
    "datatoexport <- data.bc\n",
    "\n",
    "# Collect some common metadata (e.g. from variable uas)\n",
    "dates <- datatoexport[[1]]$Dates\n",
    "xycoords <- getCoordinates(datatoexport[[1]])\n",
    "\n",
    "# Give format to dates\n",
    "yymmdd <- as.Date(dates$start)\n",
    "hhmmss <- format(as.POSIXlt(dates$start), format = \"%H:%M:%S\") \n",
    "\n",
    "# Define metadata to generate the file name\n",
    "ClimateModelName <- dataset\n",
    "ExperimentName <- \"seasonal\"\n",
    "freq <- \"day\"\n",
    "\n",
    "# Save a single file for each member\n",
    "for (i in mem) {\n",
    "  # Build data.frame for a single member\n",
    "  single.member <- lapply(datatoexport, function(x) subsetGrid(x, members = i))\n",
    "  single.member <- lapply(single.member, function(x) x$Data)\n",
    "  # Remove unwanted variables\n",
    "  single.member[\"rsds\"] <- NULL\n",
    "  single.member[\"rlds\"] <- NULL\n",
    "  # data.frame creation\n",
    "  df <- data.frame(c(list(\"dates1\" = yymmdd, \"dates2\" = hhmmss)), single.member)\n",
    "  if (i < 10) {\n",
    "    member <- paste0(\"member0\", i, sep = \"\", collapse = NULL)\n",
    "  } else {\n",
    "    member <- paste0(\"member\", i, sep = \"\", collapse = NULL)\n",
    "  }    \n",
    "  startTime <- format(as.POSIXlt(yymmdd[1]), format = \"%Y%m%d\")\n",
    "  endTime <- format(tail(as.POSIXlt(yymmdd), n = 1), format = \"%Y%m%d\")\n",
    "  dirName <- paste0(dir.data, lake_id, \"/CLIMATE/\", lake_id, \"_\", institution, \"_\", ClimateModelName, \"_\", ExperimentName, \"_\", member, \"_\", freq,\"_\", startTime, \"-\", endTime, \"/\", sep = \"\", collapse = NULL)\n",
    "  dir.create(dirName, showWarnings = TRUE, recursive = TRUE, mode = \"0777\")\n",
    "  write.table(df, paste0(dirName, \"meteo_file.dat\", sep = \"\", collapse = NULL), sep = \"\\t\", row.names = FALSE, col.names = FALSE, quote = FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Late summer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1. Select dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(java.parameters = \"-Xmx8000m\")\n",
    "\n",
    "# Define the members\n",
    "mem <- 1:15\n",
    "# Define the lead month\n",
    "lead.month <- 0\n",
    "# Define period and season\n",
    "season <- c(8,9,10)  # Late summer\n",
    "\n",
    "# Define the dataset \n",
    "dataset <- \"System4_seasonal_15\" # or \"CFSv2_seasonal\"\n",
    "\n",
    "# Check available variables in the dataset (System4)  \n",
    "di <- dataInventory(\"http://www.meteo.unican.es/tds5/dodsC/system4/System4_Seasonal_15Members.ncml\") # or \"http://meteo.unican.es/tds5/dodsC/cfsrr/CFSv2_Seasonal.ncml\"\n",
    "names(di)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2. Data loading and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the observational data (change to your local path).\n",
    "dir.Rdata.obs <- \"/home/jovyan/projects/watexr/Rdata/PIK_Obs-EWEMBI_1_2_3_4_5_6_7_8_9_10_11_12_uas_vas_ps_tas_pr_rsds_rlds_hurs_petH.rda\"\n",
    "obs.data <- get(load(dir.Rdata.obs))\n",
    "\n",
    "# Define the variables to be loaded (the same as in the observational data, \n",
    "# except clould cover (cc) and evapotranspiration (petH))\n",
    "sapply(obs.data, function(x) getVarNames(x)) # to check the variables in the observational data.\n",
    "variables <- c(\"uas\", \"vas\", \"ps\", \"tas\", \"pr\", \"rsds\", \"rlds\", \"hurs\")\n",
    "\n",
    "# Define daily aggregation function for each variable selected\n",
    "aggr.fun <- c(\"mean\", \"mean\", \"mean\", \"mean\", \"sum\", \"mean\", \"mean\", \"mean\")\n",
    "\n",
    "# Load seasonal forecast data (System4 or CFS) with function loadECOMS\n",
    "# Data is loaded in a loop (función lapply) to load all variables in a single code line.\n",
    "# A list of grids is obtained, each slot in the list corresponds to a variable\n",
    "data.prelim <- lapply(1:length(variables), function(x) loadECOMS(dataset, var = variables[x], years = years, \n",
    "                                                          members = mem, leadMonth = lead.month,\n",
    "                                                          lonLim = lonLim, latLim = latLim, season = season, \n",
    "                                                          time = \"DD\", aggr.d = aggr.fun[x]))\n",
    "names(data.prelim) <- variables\n",
    "\n",
    "# Bilinear interpolation of the data to the location of the lake\n",
    "data.interp <- lapply(data.prelim, function(x) interpGrid(x, new.coordinates = lake, \n",
    "                                                          method = \"bilinear\", \n",
    "                                                          bilin.method = \"akima\"))\n",
    "\n",
    "# Convert pressure units to millibars with function udConvertGrid from package convertR.\n",
    "data.interp$ps <- udConvertGrid(data.interp$ps, new.units = \"millibars\")\n",
    "\n",
    "## Compute cloud cover with function rad2cc\n",
    "#clt <- rad2cc(rsds = data.interp$rsds, rlds = data.interp$rlds)\n",
    "#clt$Variable$varName <- \"cc\"\n",
    "#\n",
    "## Put all variables together\n",
    "#data <- c(data.interp, \"cc\" = list(clt))\n",
    "data <- data.interp\n",
    "\n",
    "############################################################################################\n",
    "############### RUN THE FOLLOWING CODE CHUNK IF YOU NEED POTENTIAL EVAPOTRANSPIRATION ######\n",
    "# Load needed variables \n",
    "tasmin <- loadECOMS(dataset, var = \"tasmin\", years = years, \n",
    "                    lonLim = lonLim, latLim = latLim, \n",
    "                    leadMonth = lead.month, members = mem,\n",
    "                    season = season, time = \"DD\", aggr.d = \"min\")\n",
    "tasmax <- loadECOMS(dataset, var = \"tasmax\", years = years, \n",
    "                    lonLim = lonLim, latLim = latLim, \n",
    "                    leadMonth = lead.month, members = mem,\n",
    "                    season = season, time = \"DD\", aggr.d = \"max\")\n",
    "\n",
    "# Compute potential evapotranspiration with function petGrid from package drought4R\n",
    "# For daily data the implemented method is hargreaves-samani (See ?petGrid for details):\n",
    "petH <- petGrid(tasmin = tasmin, \n",
    "                tasmax = tasmax,\n",
    "                method = \"hargreaves-samani\")\n",
    "\n",
    "# bilinear interpolation \n",
    "petH.interp <- interpGrid(petH, new.coordinates = lake, method = \"bilinear\", bilin.method = \"akima\")\n",
    "petH.interp$Variable$varName <- \"petH\"\n",
    "\n",
    "# Put all variables together\n",
    "data <- c(data, \"petH\" = list(petH.interp))\n",
    "###################### END OF THE CHUNK ####################################################\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.3. Bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset all datasets to the same Dates as the hindcast precipitation. Note that we compute daily accumulated \n",
    "# precipitation, for this reason this variable has no value for the first day of every season.  \n",
    "if (sum(names(data)==\"pr\")>0){\n",
    "  data <- lapply(1:length(data), function(x)  {intersectGrid(data[[x]], data[[which(names(data)==\"pr\")]], type = \"temporal\", which.return = 1)}) \n",
    "  names(data) <- sapply(data, function(x) getVarNames(x))\n",
    "  obs.data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 1)}) \n",
    "  names(obs.data) <- sapply(obs.data, function(x) getVarNames(x))\n",
    "} else{\n",
    "  obs.data <- lapply(1:length(obs.data), function(x)  {intersectGrid(obs.data[[x]], data[[x]], type = \"temporal\", which.return = 1)}) \n",
    "  names(obs.data) <- sapply(obs.data, function(x) getVarNames(x))  \n",
    "}\n",
    "\n",
    "# Check variable consistency\n",
    "if (!identical(names(obs.data), names(data))) stop(\"variables in obs.data and data (seasonal forecast) do not match.\")\n",
    "\n",
    "# Bias correction with leave-one-year-out (\"loo\") cross-validation\n",
    "# type ?biasCorrection in R for more info about the parameter settings for bias correction.\n",
    "data.bc.cross <- lapply(1:length(data), function(x)  {\n",
    "    precip <- FALSE\n",
    "    if (names(data)[x] == \"pr\") precip <- TRUE\n",
    "    biasCorrection(y = obs.data[[x]], x = data[[x]], \n",
    "                method = \"eqm\", cross.val = \"loo\",\n",
    "                precipitation = precip,\n",
    "                wet.threshold = 1,\n",
    "                join.members = TRUE)\n",
    "  }) \n",
    "names(data.bc.cross) <- names(data)\n",
    "                            \n",
    "# Bias correction without cross-validation\n",
    "data.bc <- lapply(1:length(data), function(v)  {\n",
    "    pre <- FALSE\n",
    "    if (names(data)[v] == \"pr\") pre <- TRUE\n",
    "    biasCorrection(y = obs.data[[v]], x = data[[v]], \n",
    "                 method = \"eqm\",\n",
    "                 precipitation = pre,\n",
    "                 wet.threshold = 1,\n",
    "                 join.members = TRUE)\n",
    "}) \n",
    "names(data.bc) <- names(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.4. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Rdata (*.rda file)\n",
    "save(data, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_raw.rda\"))\n",
    "save(data.bc.cross, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BCcross.rda\"))\n",
    "save(data.bc, file = paste0(dir.Rdata, dataset, \"_\", paste0(season, collapse = \"_\"), \"_\", paste0(names(data), collapse = \"_\"), \"_BC.rda\"))\n",
    "\n",
    "########## BUILD FINAL DATA AND EXPORT ACCORDING TO THE WATExR ARCHIVE DESIGN -----------------------\n",
    "## SEE the proposal for the WATExR Archive Design in:                                            \n",
    "## https://docs.google.com/document/d/1yzNtw9W_z_ziPQ6GrnSgD9ov5O1swnohndDTAWOgpwc/edit\n",
    "\n",
    "# Select the object to export (can be 'data.bc', 'data.bc.cross' or 'data')\n",
    "datatoexport <- data.bc\n",
    "\n",
    "# Collect some common metadata (e.g. from variable uas)\n",
    "dates <- datatoexport[[1]]$Dates\n",
    "xycoords <- getCoordinates(datatoexport[[1]])\n",
    "\n",
    "# Give format to dates\n",
    "yymmdd <- as.Date(dates$start)\n",
    "hhmmss <- format(as.POSIXlt(dates$start), format = \"%H:%M:%S\") \n",
    "\n",
    "# Define metadata to generate the file name\n",
    "ClimateModelName <- dataset\n",
    "ExperimentName <- \"seasonal\"\n",
    "freq <- \"day\"\n",
    "\n",
    "# Save a single file for each member\n",
    "for (i in mem) {\n",
    "  # Build data.frame for a single member\n",
    "  single.member <- lapply(datatoexport, function(x) subsetGrid(x, members = i))\n",
    "  single.member <- lapply(single.member, function(x) x$Data)\n",
    "  # Remove unwanted variables\n",
    "  single.member[\"rsds\"] <- NULL\n",
    "  single.member[\"rlds\"] <- NULL\n",
    "  # data.frame creation\n",
    "  df <- data.frame(c(list(\"dates1\" = yymmdd, \"dates2\" = hhmmss)), single.member)\n",
    "  if (i < 10) {\n",
    "    member <- paste0(\"member0\", i, sep = \"\", collapse = NULL)\n",
    "  } else {\n",
    "    member <- paste0(\"member\", i, sep = \"\", collapse = NULL)\n",
    "  }    \n",
    "  startTime <- format(as.POSIXlt(yymmdd[1]), format = \"%Y%m%d\")\n",
    "  endTime <- format(tail(as.POSIXlt(yymmdd), n = 1), format = \"%Y%m%d\")\n",
    "  dirName <- paste0(dir.data, lake_id, \"/CLIMATE/\", lake_id, \"_\", institution, \"_\", ClimateModelName, \"_\", ExperimentName, \"_\", member, \"_\", freq,\"_\", startTime, \"-\", endTime, \"/\", sep = \"\", collapse = NULL)\n",
    "  dir.create(dirName, showWarnings = TRUE, recursive = TRUE, mode = \"0777\")\n",
    "  write.table(df, paste0(dirName, \"meteo_file.dat\", sep = \"\", collapse = NULL), sep = \"\\t\", row.names = FALSE, col.names = FALSE, quote = FALSE)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
